{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Clean up the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "directories = [\n",
    "    (\"..\\\\dataset\\\\eclipse\", \"..\\\\new_dataset\\\\eclipse\"),\n",
    "    (\"..\\\\dataset\\\\eclipse_test\", \"..\\\\new_dataset\\\\eclipse_test\"),\n",
    "    (\"..\\\\dataset\\\\firefox\", \"..\\\\new_dataset\\\\firefox\"),\n",
    "    (\"..\\\\dataset\\\\netbeans\", \"..\\\\new_dataset\\\\netbeans\"),\n",
    "    (\"..\\\\dataset\\\\openoffice\", \"..\\\\new_dataset\\\\openoffice\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclipse.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_17112\\4157724298.py:21: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,224,225,226,227,228,229,230,231,232,233,235,236,237,238,239,240,241,242,243,244,246,247,248,249,250,251,252,253,254,255,257,258,259,260,261,262,263,264,265,266,268,269,270,271,272,273,274,275,276,277,279,280,281,283,284,285,286) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(source_dir, file_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclipse_pairs.csv\n",
      "eclipse_small.csv\n",
      "eclipse_small_pairs.csv\n",
      "eclipse_test.csv\n",
      "firefox.csv\n",
      "firefox_pairs.csv\n",
      "netbeans-Copia.csv\n",
      "netbeans.csv\n",
      "netbeans_pairs-Copia.csv\n",
      "netbeans_pairs.csv\n",
      "openoffice.csv\n",
      "openoffice_pairs.csv\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each directory\n",
    "for source_dir, target_dir in directories:\n",
    "    # Iterate over each file in the directory\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        print(file_name)\n",
    "        # Check if the file is a CSV file        \n",
    "        if file_name.endswith(\".csv\") and \"pairs\" not in file_name:\n",
    "            # Load the CSV file\n",
    "            df = pd.read_csv(os.path.join(source_dir, file_name))\n",
    "            \n",
    "            # Check if the DataFrame is empty (end of file reached)\n",
    "            if df.empty:\n",
    "                print(\"End of file reached for:\", file_name)\n",
    "                continue\n",
    "            \n",
    "            # Create a new DataFrame with four columns\n",
    "            new_df = pd.DataFrame(columns=[\"bug_id\", \"bug_severity\", \"description\", \"priority\"])\n",
    "\n",
    "            # Populate the new DataFrame with data from the loaded DataFrame\n",
    "            new_df[\"bug_id\"] = df[\"bug_id\"]\n",
    "            # if the file is firefox, skip the bug_severity column\n",
    "            if \"firefox\" in source_dir:\n",
    "                new_df[\"bug_severity\"] = \"\"\n",
    "            else:\n",
    "                new_df[\"bug_severity\"] = df[\"bug_severity\"]\n",
    "            new_df[\"description\"] = df[\"description\"]\n",
    "            new_df[\"priority\"] = df[\"priority\"]\n",
    "\n",
    "            # Save the new DataFrame to a new CSV file in the target directory\n",
    "            new_file_path = os.path.join(target_dir, file_name.replace(\".csv\", \"_new.csv\"))\n",
    "            new_df.to_csv(new_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clean up the data pairs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "directories = [\n",
    "    (\"..\\\\dataset\\\\eclipse\", \"..\\\\new_dataset\\\\eclipse\"),\n",
    "    (\"..\\\\dataset\\\\firefox\", \"..\\\\new_dataset\\\\firefox\"),\n",
    "    (\"..\\\\dataset\\\\netbeans\", \"..\\\\new_dataset\\\\netbeans\"),\n",
    "    (\"..\\\\dataset\\\\openoffice\", \"..\\\\new_dataset\\\\openoffice\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclipse.csv\n",
      "eclipse_pairs.csv\n",
      "eclipse_small.csv\n",
      "eclipse_small_pairs.csv\n",
      "firefox.csv\n",
      "firefox_pairs.csv\n",
      "netbeans-Copia.csv\n",
      "netbeans.csv\n",
      "netbeans_pairs-Copia.csv\n",
      "netbeans_pairs.csv\n",
      "openoffice.csv\n",
      "openoffice_pairs.csv\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each directory\n",
    "for source_dir, target_dir in directories:\n",
    "    # Iterate over each file in the directory\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        print(file_name)\n",
    "        # Check if the file is a CSV file and contains \"pairs\" in its name\n",
    "        if file_name.endswith(\".csv\") and \"pairs\" in file_name:\n",
    "            # Load the CSV file\n",
    "            df = pd.read_csv(os.path.join(source_dir, file_name))\n",
    "            \n",
    "            # Check if the DataFrame is empty (end of file reached)\n",
    "            if df.empty:\n",
    "                print(\"End of file reached for:\", file_name)\n",
    "                continue\n",
    "            \n",
    "            # Filter out rows where the \"duplicate\" column is empty\n",
    "            df = df.dropna(subset=['duplicate'])\n",
    "            \n",
    "            # Create a new DataFrame with two columns\n",
    "            new_df = pd.DataFrame(columns=[\"issue_id\", \"duplicate\"])\n",
    "\n",
    "            # Populate the new DataFrame with data from the loaded DataFrame\n",
    "            new_df[\"issue_id\"] = df[\"issue_id\"]\n",
    "            new_df[\"duplicate\"] = df[\"duplicate\"]\n",
    "\n",
    "            # Save the new DataFrame to a new CSV file in the target directory\n",
    "            new_file_path = os.path.join(target_dir, file_name.replace(\".csv\", \"_new.csv\"))\n",
    "            new_df.to_csv(new_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
