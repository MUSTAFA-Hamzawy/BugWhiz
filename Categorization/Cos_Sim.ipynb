{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ-_-4bROUdX",
        "outputId": "a6d4b214-44d6-4eac-8006-d96d85d11e1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nimfa\n",
            "  Downloading nimfa-1.4.0-py2.py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from nimfa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from nimfa) (1.11.4)\n",
            "Installing collected packages: nimfa\n",
            "Successfully installed nimfa-1.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install nimfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GfR4Yo-rtJZ",
        "outputId": "ba32ed60-c8ee-465a-9420-a4a12537862f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukDBCJvXqwYc",
        "outputId": "83081b6b-e762-4a5b-afce-41108c3887b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# remove the stop words from the preprocessed data using nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0rcr0kUBqwYe"
      },
      "outputs": [],
      "source": [
        "def convert_lower_case(data):\n",
        "    return str(data).lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DqVvCOicqwYe"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(data):\n",
        "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
        "    for i in symbols:\n",
        "        data = np.char.replace(data, i, ' ')\n",
        "\n",
        "    return str(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q4-p9BLIqwYf"
      },
      "outputs": [],
      "source": [
        "def remove_apostrophe(data):\n",
        "    return np.char.replace(data, \"'\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B2RoS_VXqwYf"
      },
      "outputs": [],
      "source": [
        "def remove_numbers(data):\n",
        "    return re.sub(r'\\d+', '', str(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kicK-_AdqwYf"
      },
      "outputs": [],
      "source": [
        "def remove_single_characters(tokens):\n",
        "    new_text = \"\"\n",
        "    for w in tokens:\n",
        "        if len(w) > 1:\n",
        "            new_text = new_text + \" \" + w\n",
        "    return new_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NFCFEuimqwYg"
      },
      "outputs": [],
      "source": [
        "def lemmatization(data):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = word_tokenize(data)\n",
        "    data = remove_single_characters(tokens)\n",
        "    lemmatized_output = ' '.join([lemmatizer.lemmatize(word) for word in tokens])\n",
        "    return lemmatized_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OGszj2RZqwYg"
      },
      "outputs": [],
      "source": [
        "def preprocess(data):\n",
        "    data = convert_lower_case(data)\n",
        "    data = remove_punctuation(data)\n",
        "    data = remove_apostrophe(data)\n",
        "    data = remove_numbers(data)\n",
        "    data = lemmatization(data)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwwT_5_PqwYi",
        "outputId": "c269e430-8f46-457b-d3eb-27d24be68995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                     bug_description class_name\n",
            "0  for any event on my bookmarked project option ...    Backend\n",
            "1               switch to using full ln id in urlbar   Frontend\n",
            "2  consider removing hasicon property to simplify...   Frontend\n",
            "3  method to obtain current url from webbrowsered...   Frontend\n",
            "4                fix migration fails in m sql server    Backend\n"
          ]
        }
      ],
      "source": [
        "# read the preprocessed data from the new file\n",
        "preprocessed_train_df = pd.read_csv('preprocessed_train_data2.csv')\n",
        "\n",
        "# show the first 5 rows of the preprocessed training data\n",
        "print(preprocessed_train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlvdLrF6qwYi",
        "outputId": "97499af5-7a25-43b5-fb0c-769f016fd4ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                     bug_description class_name\n",
            "0  rest api ability to list sub project for a pro...    Backend\n",
            "1  support selective text on right if set in gnom...   Frontend\n",
            "2  meta userstory ship v of pre populated topsite...   Frontend\n",
            "3  include updated on and passwd changed on colum...    Backend\n",
            "4         problem with email integration to m office    Backend\n"
          ]
        }
      ],
      "source": [
        "# read the preprocessed data from the new file\n",
        "preprocessed_test_df = pd.read_csv('preprocessed_test_data2.csv')\n",
        "\n",
        "# show the first 5 rows of the preprocessed training data\n",
        "print(preprocessed_test_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoyHEvQRbQDl",
        "outputId": "0bbdccf1-58e0-4773-b12c-8e315a16044a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# remove the stop words from the preprocessed data using nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFUU3HvrsIOl",
        "outputId": "a4591fbb-14e5-43fc-98cb-756e63af18c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for any event on my bookmarked project option not sending notification for non member bookmarked project\n",
            "event bookmarked project option sending notification non member bookmarked project\n",
            "rest api ability to list sub project for a project\n",
            "rest api ability list sub project project\n"
          ]
        }
      ],
      "source": [
        "def remove_stop_words(data):\n",
        "    tokens = word_tokenize(data)\n",
        "    data = ' '.join([i for i in tokens if not i in stop_words])\n",
        "    return data\n",
        "\n",
        "# preprocess the first report of the training data\n",
        "print(preprocess(preprocessed_train_df['bug_description'][0]))\n",
        "\n",
        "# remove the stop words from the preprocessed data\n",
        "print(remove_stop_words(preprocess(preprocessed_train_df['bug_description'][0])))\n",
        "\n",
        "# preprocess the first report of the testing data\n",
        "print(preprocess(preprocessed_test_df['bug_description'][0]))\n",
        "\n",
        "# remove the stop words from the preprocessed data\n",
        "print(remove_stop_words(preprocess(preprocessed_test_df['bug_description'][0])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1XWkNBPqwYi",
        "outputId": "3fcfb993-8602-43e4-a153-d2a98d0ed6ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                     bug_description class_name\n",
            "0  event bookmarked project option sending notifi...    Backend\n",
            "1                     switch using full ln id urlbar   Frontend\n",
            "2  consider removing hasicon property simplify st...   Frontend\n",
            "3         method obtain current url webbrowsereditor   Frontend\n",
            "4                     fix migration fails sql server    Backend\n",
            "                                     bug_description class_name\n",
            "0          rest api ability list sub project project    Backend\n",
            "1     support selective text right set gnome setting   Frontend\n",
            "2  meta userstory ship v pre populated topsites a...   Frontend\n",
            "3  include updated passwd changed column user api...    Backend\n",
            "4                   problem email integration office    Backend\n"
          ]
        }
      ],
      "source": [
        "# Convert non-string values to strings in 'bug_description' column\n",
        "preprocessed_train_df['bug_description'] = preprocessed_train_df['bug_description'].apply(lambda x: str(x))\n",
        "preprocessed_test_df['bug_description'] = preprocessed_test_df['bug_description'].apply(lambda x: str(x))\n",
        "\n",
        "# Remove stop words from 'bug_description' column\n",
        "preprocessed_train_df['bug_description'] = preprocessed_train_df['bug_description'].apply(lambda x: remove_stop_words(x))\n",
        "preprocessed_test_df['bug_description'] = preprocessed_test_df['bug_description'].apply(lambda x: remove_stop_words(x))\n",
        "\n",
        "# Show the first 5 rows of the preprocessed training data\n",
        "print(preprocessed_train_df.head())\n",
        "\n",
        "# Show the first 5 rows of the preprocessed testing data\n",
        "print(preprocessed_test_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7avA5KxfqwYi",
        "outputId": "08f0ebfe-d8a3-44d0-fdc2-6370b48dd42b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered Training Data:\n",
            "                                     bug_description class_name\n",
            "0  event bookmarked project option sending notifi...    Backend\n",
            "1                     switch using full ln id urlbar   Frontend\n",
            "2  consider removing hasicon property simplify st...   Frontend\n",
            "3         method obtain current url webbrowsereditor   Frontend\n",
            "4                     fix migration fails sql server    Backend\n",
            "\n",
            "Filtered Testing Data:\n",
            "                                     bug_description class_name\n",
            "0          rest api ability list sub project project    Backend\n",
            "1     support selective text right set gnome setting   Frontend\n",
            "2  meta userstory ship v pre populated topsites a...   Frontend\n",
            "3  include updated passwd changed column user api...    Backend\n",
            "4                   problem email integration office    Backend\n"
          ]
        }
      ],
      "source": [
        "# keep only the reports that has class_name of Frontend, Backend, Security, Documentation\n",
        "# Filter the training data\n",
        "filtered_train_df = preprocessed_train_df[\n",
        "    (preprocessed_train_df['class_name'] == 'Frontend') |\n",
        "    (preprocessed_train_df['class_name'] == 'Backend') |\n",
        "    (preprocessed_train_df['class_name'] == 'Security') |\n",
        "    (preprocessed_train_df['class_name'] == 'Documentation')\n",
        "]\n",
        "\n",
        "# Filter the testing data\n",
        "filtered_test_df = preprocessed_test_df[\n",
        "    (preprocessed_test_df['class_name'] == 'Frontend') |\n",
        "    (preprocessed_test_df['class_name'] == 'Backend') |\n",
        "    (preprocessed_test_df['class_name'] == 'Security') |\n",
        "    (preprocessed_test_df['class_name'] == 'Documentation')\n",
        "]\n",
        "\n",
        "# Show the first 5 rows of the filtered training data\n",
        "print(\"Filtered Training Data:\")\n",
        "print(filtered_train_df.head())\n",
        "\n",
        "# Show the first 5 rows of the filtered testing data\n",
        "print(\"\\nFiltered Testing Data:\")\n",
        "print(filtered_test_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYJ8iDYgqwYi",
        "outputId": "c90ebac5-09f8-4597-cedc-733b944f31ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Frontend' 'Backend' 'Security' 'Documentation']\n",
            "['Frontend' 'Backend' 'Security' 'Documentation']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_20600\\3815010096.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_train_df['class_label'] = filtered_train_df['class_name'].map(class_name_mapping)\n",
            "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_20600\\3815010096.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_test_df['class_label'] = filtered_test_df['class_name'].map(class_name_mapping)\n"
          ]
        }
      ],
      "source": [
        "# Define the mapping of class names to the desired order\n",
        "class_name_mapping = {\n",
        "    'Backend': 1,\n",
        "    'Frontend': 0,\n",
        "    'Security': 2,\n",
        "    'Documentation': 3\n",
        "}\n",
        "\n",
        "# Map class names in both training and testing data to the desired order\n",
        "filtered_train_df['class_label'] = filtered_train_df['class_name'].map(class_name_mapping)\n",
        "filtered_test_df['class_label'] = filtered_test_df['class_name'].map(class_name_mapping)\n",
        "\n",
        "# order them based on the number of class_label\n",
        "filtered_train_df = filtered_train_df.sort_values(by=['class_label'])\n",
        "filtered_test_df = filtered_test_df.sort_values(by=['class_label'])\n",
        "\n",
        "# Print the unique class names in the training data\n",
        "print(filtered_train_df['class_name'].unique())\n",
        "\n",
        "# Print the unique class names in the testing data\n",
        "print(filtered_test_df['class_name'].unique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esX-WwIwqwYj"
      },
      "source": [
        "## Feature Exraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZB99m8gvAcs",
        "outputId": "801c6041-a364-4f01-ff39-6e99a16346b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13777\n"
          ]
        }
      ],
      "source": [
        "print(len(filtered_train_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6I9uy_heqwYk"
      },
      "outputs": [],
      "source": [
        "# Define the mapping of class names to the desired order\n",
        "class_name_mapping = {\n",
        "    'Backend': 1,\n",
        "    'Frontend': 0,\n",
        "    'Security': 2,\n",
        "    'Documentation': 3\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1y5wBKOPOsDd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load X_train and X_test from files\n",
        "X_train = np.load('X_train.npy')\n",
        "X_test = np.load('X_test.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2423\n"
          ]
        }
      ],
      "source": [
        "# print number of test reports\n",
        "print(len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dwF2zikxgdeR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Report Number:  0\n",
            "Test Report Number:  1\n",
            "Test Report Number:  2\n",
            "Test Report Number:  3\n",
            "Test Report Number:  4\n",
            "Test Report Number:  5\n",
            "Test Report Number:  6\n",
            "Test Report Number:  7\n",
            "Test Report Number:  8\n",
            "Test Report Number:  9\n",
            "Test Report Number:  10\n",
            "Test Report Number:  11\n",
            "Test Report Number:  12\n",
            "Test Report Number:  13\n",
            "Test Report Number:  14\n",
            "Test Report Number:  15\n",
            "Test Report Number:  16\n",
            "Test Report Number:  17\n",
            "Test Report Number:  18\n",
            "Test Report Number:  19\n",
            "Test Report Number:  20\n",
            "Test Report Number:  21\n",
            "Test Report Number:  22\n",
            "Test Report Number:  23\n",
            "Test Report Number:  24\n",
            "Test Report Number:  25\n",
            "Test Report Number:  26\n",
            "Test Report Number:  27\n",
            "Test Report Number:  28\n",
            "Test Report Number:  29\n",
            "Test Report Number:  30\n",
            "Test Report Number:  31\n",
            "Test Report Number:  32\n",
            "Test Report Number:  33\n",
            "Test Report Number:  34\n",
            "Test Report Number:  35\n",
            "Test Report Number:  36\n",
            "Test Report Number:  37\n",
            "Test Report Number:  38\n",
            "Test Report Number:  39\n",
            "Test Report Number:  40\n",
            "Test Report Number:  41\n",
            "Test Report Number:  42\n",
            "Test Report Number:  43\n",
            "Test Report Number:  44\n",
            "Test Report Number:  45\n",
            "Test Report Number:  46\n",
            "Test Report Number:  47\n",
            "Test Report Number:  48\n",
            "Test Report Number:  49\n",
            "Test Report Number:  50\n",
            "Test Report Number:  51\n",
            "Test Report Number:  52\n",
            "Test Report Number:  53\n",
            "Test Report Number:  54\n",
            "Test Report Number:  55\n",
            "Test Report Number:  56\n",
            "Test Report Number:  57\n",
            "Test Report Number:  58\n",
            "Test Report Number:  59\n",
            "Test Report Number:  60\n",
            "Test Report Number:  61\n",
            "Test Report Number:  62\n",
            "Test Report Number:  63\n",
            "Test Report Number:  64\n",
            "Test Report Number:  65\n",
            "Test Report Number:  66\n",
            "Test Report Number:  67\n",
            "Test Report Number:  68\n",
            "Test Report Number:  69\n",
            "Test Report Number:  70\n",
            "Test Report Number:  71\n",
            "Test Report Number:  72\n",
            "Test Report Number:  73\n",
            "Test Report Number:  74\n",
            "Test Report Number:  75\n",
            "Test Report Number:  76\n",
            "Test Report Number:  77\n",
            "Test Report Number:  78\n",
            "Test Report Number:  79\n",
            "Test Report Number:  80\n",
            "Test Report Number:  81\n",
            "Test Report Number:  82\n",
            "Test Report Number:  83\n",
            "Test Report Number:  84\n",
            "Test Report Number:  85\n",
            "Test Report Number:  86\n",
            "Test Report Number:  87\n",
            "Test Report Number:  88\n",
            "Test Report Number:  89\n",
            "Test Report Number:  90\n",
            "Test Report Number:  91\n",
            "Test Report Number:  92\n",
            "Test Report Number:  93\n",
            "Test Report Number:  94\n",
            "Test Report Number:  95\n",
            "Test Report Number:  96\n",
            "Test Report Number:  97\n",
            "Test Report Number:  98\n",
            "Test Report Number:  99\n",
            "Test Report Number:  100\n",
            "Test Report Number:  101\n",
            "Test Report Number:  102\n",
            "Test Report Number:  103\n",
            "Test Report Number:  104\n",
            "Test Report Number:  105\n",
            "Test Report Number:  106\n",
            "Test Report Number:  107\n",
            "Test Report Number:  108\n",
            "Test Report Number:  109\n",
            "Test Report Number:  110\n",
            "Test Report Number:  111\n",
            "Test Report Number:  112\n",
            "Test Report Number:  113\n",
            "Test Report Number:  114\n",
            "Test Report Number:  115\n",
            "Test Report Number:  116\n",
            "Test Report Number:  117\n",
            "Test Report Number:  118\n",
            "Test Report Number:  119\n",
            "Test Report Number:  120\n",
            "Test Report Number:  121\n",
            "Test Report Number:  122\n",
            "Test Report Number:  123\n",
            "Test Report Number:  124\n",
            "Test Report Number:  125\n",
            "Test Report Number:  126\n",
            "Test Report Number:  127\n",
            "Test Report Number:  128\n",
            "Test Report Number:  129\n",
            "Test Report Number:  130\n",
            "Test Report Number:  131\n",
            "Test Report Number:  132\n",
            "Test Report Number:  133\n",
            "Test Report Number:  134\n",
            "Test Report Number:  135\n",
            "Test Report Number:  136\n",
            "Test Report Number:  137\n",
            "Test Report Number:  138\n",
            "Test Report Number:  139\n",
            "Test Report Number:  140\n",
            "Test Report Number:  141\n",
            "Test Report Number:  142\n",
            "Test Report Number:  143\n",
            "Test Report Number:  144\n",
            "Test Report Number:  145\n",
            "Test Report Number:  146\n",
            "Test Report Number:  147\n",
            "Test Report Number:  148\n",
            "Test Report Number:  149\n",
            "Test Report Number:  150\n",
            "Test Report Number:  151\n",
            "Test Report Number:  152\n",
            "Test Report Number:  153\n",
            "Test Report Number:  154\n",
            "Test Report Number:  155\n",
            "Test Report Number:  156\n",
            "Test Report Number:  157\n",
            "Test Report Number:  158\n",
            "Test Report Number:  159\n",
            "Test Report Number:  160\n",
            "Test Report Number:  161\n",
            "Test Report Number:  162\n",
            "Test Report Number:  163\n",
            "Test Report Number:  164\n",
            "Test Report Number:  165\n",
            "Test Report Number:  166\n",
            "Test Report Number:  167\n",
            "Test Report Number:  168\n",
            "Test Report Number:  169\n",
            "Test Report Number:  170\n",
            "Test Report Number:  171\n",
            "Test Report Number:  172\n",
            "Test Report Number:  173\n",
            "Test Report Number:  174\n",
            "Test Report Number:  175\n",
            "Test Report Number:  176\n",
            "Test Report Number:  177\n",
            "Test Report Number:  178\n",
            "Test Report Number:  179\n",
            "Test Report Number:  180\n",
            "Test Report Number:  181\n",
            "Test Report Number:  182\n",
            "Test Report Number:  183\n",
            "Test Report Number:  184\n",
            "Test Report Number:  185\n",
            "Test Report Number:  186\n",
            "Test Report Number:  187\n",
            "Test Report Number:  188\n",
            "Test Report Number:  189\n",
            "Test Report Number:  190\n",
            "Test Report Number:  191\n",
            "Test Report Number:  192\n",
            "Test Report Number:  193\n",
            "Test Report Number:  194\n",
            "Test Report Number:  195\n",
            "Test Report Number:  196\n",
            "Test Report Number:  197\n",
            "Test Report Number:  198\n",
            "Test Report Number:  199\n",
            "Test Report Number:  200\n",
            "Test Report Number:  201\n",
            "Test Report Number:  202\n",
            "Test Report Number:  203\n",
            "Test Report Number:  204\n",
            "Test Report Number:  205\n",
            "Test Report Number:  206\n",
            "Test Report Number:  207\n",
            "Test Report Number:  208\n",
            "Test Report Number:  209\n",
            "Test Report Number:  210\n",
            "Test Report Number:  211\n",
            "Test Report Number:  212\n",
            "Test Report Number:  213\n",
            "Test Report Number:  214\n",
            "Test Report Number:  215\n",
            "Test Report Number:  216\n",
            "Test Report Number:  217\n",
            "Test Report Number:  218\n",
            "Test Report Number:  219\n",
            "Test Report Number:  220\n",
            "Test Report Number:  221\n",
            "Test Report Number:  222\n",
            "Test Report Number:  223\n",
            "Test Report Number:  224\n",
            "Test Report Number:  225\n",
            "Test Report Number:  226\n",
            "Test Report Number:  227\n",
            "Test Report Number:  228\n",
            "Test Report Number:  229\n",
            "Test Report Number:  230\n",
            "Test Report Number:  231\n",
            "Test Report Number:  232\n",
            "Test Report Number:  233\n",
            "Test Report Number:  234\n",
            "Test Report Number:  235\n",
            "Test Report Number:  236\n",
            "Test Report Number:  237\n",
            "Test Report Number:  238\n",
            "Test Report Number:  239\n",
            "Test Report Number:  240\n",
            "Test Report Number:  241\n",
            "Test Report Number:  242\n",
            "Test Report Number:  243\n",
            "Test Report Number:  244\n",
            "Test Report Number:  245\n",
            "Test Report Number:  246\n",
            "Test Report Number:  247\n",
            "Test Report Number:  248\n",
            "Test Report Number:  249\n",
            "Test Report Number:  250\n",
            "Test Report Number:  251\n",
            "Test Report Number:  252\n",
            "Test Report Number:  253\n",
            "Test Report Number:  254\n",
            "Test Report Number:  255\n",
            "Test Report Number:  256\n",
            "Test Report Number:  257\n",
            "Test Report Number:  258\n",
            "Test Report Number:  259\n",
            "Test Report Number:  260\n",
            "Test Report Number:  261\n",
            "Test Report Number:  262\n",
            "Test Report Number:  263\n",
            "Test Report Number:  264\n",
            "Test Report Number:  265\n",
            "Test Report Number:  266\n",
            "Test Report Number:  267\n",
            "Test Report Number:  268\n",
            "Test Report Number:  269\n",
            "Test Report Number:  270\n",
            "Test Report Number:  271\n",
            "Test Report Number:  272\n",
            "Test Report Number:  273\n",
            "Test Report Number:  274\n",
            "Test Report Number:  275\n",
            "Test Report Number:  276\n",
            "Test Report Number:  277\n",
            "Test Report Number:  278\n",
            "Test Report Number:  279\n",
            "Test Report Number:  280\n",
            "Test Report Number:  281\n",
            "Test Report Number:  282\n",
            "Test Report Number:  283\n",
            "Test Report Number:  284\n",
            "Test Report Number:  285\n",
            "Test Report Number:  286\n",
            "Test Report Number:  287\n",
            "Test Report Number:  288\n",
            "Test Report Number:  289\n",
            "Test Report Number:  290\n",
            "Test Report Number:  291\n",
            "Test Report Number:  292\n",
            "Test Report Number:  293\n",
            "Test Report Number:  294\n",
            "Test Report Number:  295\n",
            "Test Report Number:  296\n",
            "Test Report Number:  297\n",
            "Test Report Number:  298\n",
            "Test Report Number:  299\n",
            "Test Report Number:  300\n",
            "Test Report Number:  301\n",
            "Test Report Number:  302\n",
            "Test Report Number:  303\n",
            "Test Report Number:  304\n",
            "Test Report Number:  305\n",
            "Test Report Number:  306\n",
            "Test Report Number:  307\n",
            "Test Report Number:  308\n",
            "Test Report Number:  309\n",
            "Test Report Number:  310\n",
            "Test Report Number:  311\n",
            "Test Report Number:  312\n",
            "Test Report Number:  313\n",
            "Test Report Number:  314\n",
            "Test Report Number:  315\n",
            "Test Report Number:  316\n",
            "Test Report Number:  317\n",
            "Test Report Number:  318\n",
            "Test Report Number:  319\n",
            "Test Report Number:  320\n",
            "Test Report Number:  321\n",
            "Test Report Number:  322\n",
            "Test Report Number:  323\n",
            "Test Report Number:  324\n",
            "Test Report Number:  325\n",
            "Test Report Number:  326\n",
            "Test Report Number:  327\n",
            "Test Report Number:  328\n",
            "Test Report Number:  329\n",
            "Test Report Number:  330\n",
            "Test Report Number:  331\n",
            "Test Report Number:  332\n",
            "Test Report Number:  333\n",
            "Test Report Number:  334\n",
            "Test Report Number:  335\n",
            "Test Report Number:  336\n",
            "Test Report Number:  337\n",
            "Test Report Number:  338\n",
            "Test Report Number:  339\n",
            "Test Report Number:  340\n",
            "Test Report Number:  341\n",
            "Test Report Number:  342\n",
            "Test Report Number:  343\n",
            "Test Report Number:  344\n",
            "Test Report Number:  345\n",
            "Test Report Number:  346\n",
            "Test Report Number:  347\n",
            "Test Report Number:  348\n",
            "Test Report Number:  349\n",
            "Test Report Number:  350\n",
            "Test Report Number:  351\n",
            "Test Report Number:  352\n",
            "Test Report Number:  353\n",
            "Test Report Number:  354\n",
            "Test Report Number:  355\n",
            "Test Report Number:  356\n",
            "Test Report Number:  357\n",
            "Test Report Number:  358\n",
            "Test Report Number:  359\n",
            "Test Report Number:  360\n",
            "Test Report Number:  361\n",
            "Test Report Number:  362\n",
            "Test Report Number:  363\n",
            "Test Report Number:  364\n",
            "Test Report Number:  365\n",
            "Test Report Number:  366\n",
            "Test Report Number:  367\n",
            "Test Report Number:  368\n",
            "Test Report Number:  369\n",
            "Test Report Number:  370\n",
            "Test Report Number:  371\n",
            "Test Report Number:  372\n",
            "Test Report Number:  373\n",
            "Test Report Number:  374\n",
            "Test Report Number:  375\n",
            "Test Report Number:  376\n",
            "Test Report Number:  377\n",
            "Test Report Number:  378\n",
            "Test Report Number:  379\n",
            "Test Report Number:  380\n",
            "Test Report Number:  381\n",
            "Test Report Number:  382\n",
            "Test Report Number:  383\n",
            "Test Report Number:  384\n",
            "Test Report Number:  385\n",
            "Test Report Number:  386\n",
            "Test Report Number:  387\n",
            "Test Report Number:  388\n",
            "Test Report Number:  389\n",
            "Test Report Number:  390\n",
            "Test Report Number:  391\n",
            "Test Report Number:  392\n",
            "Test Report Number:  393\n",
            "Test Report Number:  394\n",
            "Test Report Number:  395\n",
            "Test Report Number:  396\n",
            "Test Report Number:  397\n",
            "Test Report Number:  398\n",
            "Test Report Number:  399\n",
            "Test Report Number:  400\n",
            "Test Report Number:  401\n",
            "Test Report Number:  402\n",
            "Test Report Number:  403\n",
            "Test Report Number:  404\n",
            "Test Report Number:  405\n",
            "Test Report Number:  406\n",
            "Test Report Number:  407\n",
            "Test Report Number:  408\n",
            "Test Report Number:  409\n",
            "Test Report Number:  410\n",
            "Test Report Number:  411\n",
            "Test Report Number:  412\n",
            "Test Report Number:  413\n",
            "Test Report Number:  414\n",
            "Test Report Number:  415\n",
            "Test Report Number:  416\n",
            "Test Report Number:  417\n",
            "Test Report Number:  418\n",
            "Test Report Number:  419\n",
            "Test Report Number:  420\n",
            "Test Report Number:  421\n",
            "Test Report Number:  422\n",
            "Test Report Number:  423\n",
            "Test Report Number:  424\n",
            "Test Report Number:  425\n",
            "Test Report Number:  426\n",
            "Test Report Number:  427\n",
            "Test Report Number:  428\n",
            "Test Report Number:  429\n",
            "Test Report Number:  430\n",
            "Test Report Number:  431\n",
            "Test Report Number:  432\n",
            "Test Report Number:  433\n",
            "Test Report Number:  434\n",
            "Test Report Number:  435\n",
            "Test Report Number:  436\n",
            "Test Report Number:  437\n",
            "Test Report Number:  438\n",
            "Test Report Number:  439\n",
            "Test Report Number:  440\n",
            "Test Report Number:  441\n",
            "Test Report Number:  442\n",
            "Test Report Number:  443\n",
            "Test Report Number:  444\n",
            "Test Report Number:  445\n",
            "Test Report Number:  446\n",
            "Test Report Number:  447\n",
            "Test Report Number:  448\n",
            "Test Report Number:  449\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m train_class_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrontend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSecurity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDocumentation\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Predict the class labels for the test data\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m predicted_class_labels \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_class_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Print the predicted class labels\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_class_labels)\n",
            "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36mpredict_class\u001b[1;34m(test_data, train_data, train_class_labels)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_report \u001b[38;5;129;01min\u001b[39;00m train_data:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Reshape the train report to ensure it's a 2D array\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     train_report \u001b[38;5;241m=\u001b[39m train_report\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m     similarity_score \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_report\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_report\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     similarity_scores\u001b[38;5;241m.\u001b[39mappend(similarity_score)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Compute the average similarity score for each class\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1395\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m-> 1395\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n\u001b[0;32m   1397\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m X_normalized\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1817\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a supported axis\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m axis)\n\u001b[1;32m-> 1817\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthe normalize function\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1825\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mT\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:950\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    948\u001b[0m     \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[0;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmay_share_memory(array, array_orig):\n\u001b[1;32m--> 950\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;66;03m# always make a copy for non-numpy arrays\u001b[39;00m\n\u001b[0;32m    955\u001b[0m     array \u001b[38;5;241m=\u001b[39m _asarray_with_order(\n\u001b[0;32m    956\u001b[0m         array, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xp\u001b[38;5;241m=\u001b[39mxp\n\u001b[0;32m    957\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:186\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:73\u001b[0m, in \u001b[0;36m_NumPyApiWrapper.asarray\u001b[1;34m(self, x, dtype, device, copy)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21masarray\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Support copy in NumPy namespace\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39masarray(x, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Define the class labels for training data\n",
        "train_class_labels = ['Frontend', 'Backend', 'Security', 'Documentation']\n",
        "\n",
        "# Iterate over each report of test data,\n",
        "# then compute the cosine similarity with each report of training data of each class\n",
        "# then average the similarity scores for each class\n",
        "def predict_class(test_data, train_data, train_class_labels):\n",
        "    # Initialize the list to store the average similarity scores for each class\n",
        "    avg_similarity_scores = []\n",
        "    counter = 0\n",
        "\n",
        "    # Iterate over each report in the test data\n",
        "    for test_report in test_data:\n",
        "        # Reshape the test report to ensure it's a 2D array\n",
        "        test_report = test_report.reshape(1, -1)\n",
        "\n",
        "        # Initialize the list to store the similarity scores for each class\n",
        "        similarity_scores = []\n",
        "        print(\"Test Report Number: \", counter)\n",
        "        counter += 1\n",
        "\n",
        "        # Compute the cosine similarity between the test report and each report in the training data\n",
        "        for train_report in train_data:\n",
        "            # Reshape the train report to ensure it's a 2D array\n",
        "            train_report = train_report.reshape(1, -1)\n",
        "\n",
        "            similarity_score = cosine_similarity(test_report, train_report)\n",
        "            similarity_scores.append(similarity_score)\n",
        "\n",
        "        # Compute the average similarity score for each class\n",
        "        similarity_scores = np.array(similarity_scores)\n",
        "        avg_similarity_scores.append(np.mean(similarity_scores, axis=0))\n",
        "\n",
        "    # Convert the list to a NumPy array\n",
        "    avg_similarity_scores = np.array(avg_similarity_scores)\n",
        "\n",
        "    # Predict the class with the highest average similarity score\n",
        "    predicted_class_indices = np.argmax(avg_similarity_scores, axis=1)\n",
        "\n",
        "    # Map numerical indices to class labels\n",
        "    predicted_class_labels = [train_class_labels[i] for i in predicted_class_indices]\n",
        "\n",
        "    # Return the predicted class labels\n",
        "    return predicted_class_labels\n",
        "\n",
        "# Assuming you have obtained GloVe embeddings and stored them in X_test and X_train\n",
        "# Define the class labels for training data\n",
        "train_class_labels = ['Frontend', 'Backend', 'Security', 'Documentation']\n",
        "\n",
        "# Predict the class labels for the test data\n",
        "predicted_class_labels = predict_class(X_test, X_train, train_class_labels)\n",
        "\n",
        "# Print the predicted class labels\n",
        "print(predicted_class_labels)\n",
        "\n",
        "# Print the actual class labels\n",
        "print(filtered_test_df['class_name'])\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(filtered_test_df['class_name'], predicted_class_labels))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(confusion_matrix(filtered_test_df['class_name'], predicted_class_labels))\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = np.mean(filtered_test_df['class_name'] == predicted_class_labels)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate and print the precision, recall, and F1 score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(filtered_test_df['class_name'], predicted_class_labels, average='weighted')\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64zNE7LTw-q6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
