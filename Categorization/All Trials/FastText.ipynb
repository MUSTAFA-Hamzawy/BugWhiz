{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordNetLemmatizer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfasttext\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m product\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load training and testing data\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import fasttext\n",
    "from itertools import product\n",
    "\n",
    "# Load training and testing data\n",
    "train_path = 'train.xlsx'\n",
    "test_path = 'test.xlsx'\n",
    "train_df = pd.read_excel(train_path)\n",
    "test_df = pd.read_excel(test_path)\n",
    "\n",
    "# Preprocessing functions\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = word_tokenize(text)  # Tokenize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]  # Lemmatize\n",
    "    return ' '.join(text)\n",
    "\n",
    "# Preprocess training and testing data\n",
    "train_df['bug_description'] = train_df['report'].apply(preprocess)\n",
    "test_df['bug_description'] = test_df['report'].apply(preprocess)\n",
    "\n",
    "# Define a function to train a FastText model\n",
    "def train_fasttext_model(train_df, test_df, ngram_range=(2, 2), word_ngrams=1):\n",
    "    train_data = []\n",
    "    for index, row in train_df.iterrows():\n",
    "        train_data.append(f\"__label__{row['class_name']} {row['bug_description']}\")\n",
    "    model = fasttext.train_supervised(input=train_data, wordNgrams=word_ngrams, minn=ngram_range[0], maxn=ngram_range[1])\n",
    "    test_data = [row['bug_description'] for index, row in test_df.iterrows()]\n",
    "    true_labels = [row['class_name'] for index, row in test_df.iterrows()]\n",
    "    predicted_labels = [model.predict(text)[0][0].replace('__label__', '') for text in test_data]\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(true_labels, predicted_labels))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(true_labels, predicted_labels))\n",
    "\n",
    "# Define a function to evaluate FastText models with different n-gram ranges\n",
    "def evaluate_fasttext_models(train_df, test_df):\n",
    "    ngram_ranges = [(i, j) for i in range(2, 5) for j in range(2, 10)]\n",
    "    word_ngrams = [1]  # Change this if you want to try different values\n",
    "    for ngram_range, word_ngram in product(ngram_ranges, word_ngrams):\n",
    "        print(f\"Evaluating with ngram_range: {ngram_range}, word_ngrams: {word_ngram}\")\n",
    "        train_fasttext_model(train_df, test_df, ngram_range=ngram_range, word_ngrams=word_ngram)\n",
    "\n",
    "# Evaluate FastText models\n",
    "evaluate_fasttext_models(train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
