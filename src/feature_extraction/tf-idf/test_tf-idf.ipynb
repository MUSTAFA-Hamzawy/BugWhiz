{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK stopwords corpus if not already downloaded\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "directories = [\n",
    "    (\"..\\\\new_dataset\\\\eclipse\", \"..\\\\BOW_dataset\\\\eclipse\"),\n",
    "    (\"..\\\\new_dataset\\\\firefox\", \"..\\\\BOW_dataset\\\\firefox\"),\n",
    "    (\"..\\\\new_dataset\\\\netbeans\", \"..\\\\BOW_dataset\\\\netbeans\"),\n",
    "    (\"..\\\\new_dataset\\\\openoffice\", \"..\\\\BOW_dataset\\\\openoffice\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess bug description text\n",
    "def preprocess_bug_description(description):\n",
    "\n",
    "    # convert description to string\n",
    "    description = str(description)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    description = description.lower()\n",
    "\n",
    "    # Remove punctuation and special characters\n",
    "    description = re.sub(r'[^a-zA-Z0-9\\s]', '', description)\n",
    "\n",
    "    # Remove numbers\n",
    "    description = re.sub(r'\\b\\d+\\b', '', description)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    description = re.sub(r'\\s+', ' ', description)\n",
    "\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Bug Reports\n",
    "def preprocess_bug_reports(bug_reports):\n",
    "    preprocessed_reports = []\n",
    "    for report in bug_reports:\n",
    "        # Implement your preprocessing steps here\n",
    "        preprocessed_report = preprocess_bug_description(report)\n",
    "        preprocessed_reports.append(preprocessed_report)\n",
    "    return preprocessed_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Similarity\n",
    "def calculate_similarity(bow_vectors):\n",
    "    # Calculate cosine similarity between each pair of bug reports\n",
    "    num_reports = bow_vectors.shape[0]\n",
    "    similarities = []\n",
    "    for i in range(num_reports):\n",
    "        for j in range(i+1, num_reports):\n",
    "            similarity_score = cosine_similarity(bow_vectors[i], bow_vectors[j])[0][0]\n",
    "            similarities.append(similarity_score)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tfidf_similarity function\n",
    "def tfidf_similarity(bug1, bug2):\n",
    "    # Initialize the TF-IDF vectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Apply TF-IDF to bug reports\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([bug1, bug2])\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get bug descriptions based on bug IDs\n",
    "def get_bug_description(bug_id, file_data):\n",
    "\n",
    "    # convert to string\n",
    "    bug_id = int(bug_id)\n",
    "    bug_id = str(bug_id)\n",
    "    \n",
    "    # if id is not found in the dataset, return None\n",
    "    # convert the bug_id column to string\n",
    "    file_data['bug_id'] = file_data['bug_id'].astype(str)\n",
    "    \n",
    "    if bug_id not in file_data['bug_id'].values:\n",
    "        return None\n",
    "    \n",
    "    return file_data[file_data['bug_id'] == bug_id]['description'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs file loaded: eclipse_new_similarity.csv\n",
      "Original bug reports file loaded: eclipse_new.csv\n",
      "214301\n",
      "214611\n",
      "Iterations: 0\n",
      "214445\n",
      "214451\n",
      "Iterations: 1\n",
      "214466\n",
      "214452\n",
      "Iterations: 2\n",
      "214577\n",
      "217601\n",
      "Iterations: 3\n",
      "214862\n",
      "214759\n",
      "Iterations: 4\n",
      "215052\n",
      "214414\n",
      "Iterations: 5\n",
      "215052\n",
      "213299\n",
      "Iterations: 6\n",
      "214411\n",
      "216725\n",
      "Iterations: 7\n",
      "214411\n",
      "216663\n",
      "Iterations: 8\n",
      "214411\n",
      "210304\n",
      "Iterations: 9\n",
      "214305\n",
      "214303\n",
      "Iterations: 10\n",
      "214305\n",
      "214611\n",
      "Iterations: 11\n",
      "214305\n",
      "214301\n",
      "Iterations: 12\n",
      "214306\n",
      "214303\n",
      "Iterations: 13\n",
      "214306\n",
      "214304\n",
      "Iterations: 14\n",
      "214306\n",
      "214305\n",
      "Iterations: 15\n",
      "214306\n",
      "214611\n",
      "Iterations: 16\n",
      "214306\n",
      "214301\n",
      "Iterations: 17\n",
      "215040\n",
      "214988\n",
      "Iterations: 18\n",
      "215040\n",
      "214990\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Get descriptions of the bugs\u001b[39;00m\n\u001b[0;32m     36\u001b[0m description1 \u001b[38;5;241m=\u001b[39m get_bug_description(issue_id, bug_reports_file)\n\u001b[1;32m---> 37\u001b[0m description2 \u001b[38;5;241m=\u001b[39m \u001b[43mget_bug_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mduplicate_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbug_reports_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m#print(\"description1 is:\", description1)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m#print(\"description2 is:\", description2)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# if one of the descriptions is None, skip the comparison\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m description1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m description2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36mget_bug_description\u001b[1;34m(bug_id, file_data)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(bug_id)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# if id is not found in the dataset, return None\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# convert the bug_id column to string\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbug_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbug_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bug_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m file_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbug_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4187\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4184\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[0;32m   4185\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m-> 4187\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4146\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis), key, value)\n\u001b[0;32m   4145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iset_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4148\u001b[0m \u001b[38;5;66;03m# check if we are modifying a copy\u001b[39;00m\n\u001b[0;32m   4149\u001b[0m \u001b[38;5;66;03m# try to set first as we want an invalid\u001b[39;00m\n\u001b[0;32m   4150\u001b[0m \u001b[38;5;66;03m# value exception to occur first\u001b[39;00m\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4136\u001b[0m, in \u001b[0;36mDataFrame._iset_item_mgr\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   4132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_iset_item_mgr\u001b[39m(\n\u001b[0;32m   4133\u001b[0m     \u001b[38;5;28mself\u001b[39m, loc: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray, value, inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   4134\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4135\u001b[0m     \u001b[38;5;66;03m# when called from _set_item_mgr loc can be anything returned from get_loc\u001b[39;00m\n\u001b[1;32m-> 4136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1268\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1266\u001b[0m     removed_blknos\u001b[38;5;241m.\u001b[39mappend(blkno_l)\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1268\u001b[0m     nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1269\u001b[0m     blocks_tup \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[:blkno_l] \u001b[38;5;241m+\u001b[39m (nb,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[blkno_l \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :]\n\u001b[0;32m   1271\u001b[0m     )\n\u001b[0;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m blocks_tup\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:1921\u001b[0m, in \u001b[0;36mNumpyBlock.delete\u001b[1;34m(self, loc)\u001b[0m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelete\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[1;32m-> 1921\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1922\u001b[0m     mgr_locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr_locs\u001b[38;5;241m.\u001b[39mdelete(loc)\n\u001b[0;32m   1923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(values, placement\u001b[38;5;241m=\u001b[39mmgr_locs, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdelete\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\function_base.py:5217\u001b[0m, in \u001b[0;36mdelete\u001b[1;34m(arr, obj, axis)\u001b[0m\n\u001b[0;32m   5215\u001b[0m     obj \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m N\n\u001b[0;32m   5216\u001b[0m newshape[axis] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5217\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrorder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5218\u001b[0m slobj[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, obj)\n\u001b[0;32m   5219\u001b[0m new[\u001b[38;5;28mtuple\u001b[39m(slobj)] \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;28mtuple\u001b[39m(slobj)]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Iterate over each directory\n",
    "for source_dir, target_dir in directories:\n",
    "\n",
    "    # Iterate over each file in the directory\n",
    "    for file_name in os.listdir(target_dir):\n",
    "\n",
    "        # Check if the file is a CSV file and contains \"_new_similarity\" in its name\n",
    "        if file_name.endswith(\".csv\") and \"_new_similarity\" in file_name:\n",
    "\n",
    "            # Load the CSV file with similarity data\n",
    "            pairs_data = pd.read_csv(os.path.join(target_dir, file_name))\n",
    "            print(\"Pairs file loaded:\", file_name)\n",
    "\n",
    "            # Load the original bug reports file\n",
    "            original_file_name = file_name.replace(\"_new_similarity.csv\", \"_new.csv\")\n",
    "            bug_reports_file = pd.read_csv(os.path.join(source_dir, original_file_name))\n",
    "            print(\"Original bug reports file loaded:\", original_file_name)\n",
    "\n",
    "            # Check if the DataFrame is empty (end of file reached)\n",
    "            if pairs_data.empty:\n",
    "                print(\"End of file reached for:\", file_name)\n",
    "                continue\n",
    "\n",
    "            # Iterate through each pair of bug reports\n",
    "            for index, row in pairs_data.iterrows():\n",
    "                issue_id = row['issue_id']\n",
    "                duplicate_id = row['duplicate_id']\n",
    "                \n",
    "                #print (\"issue_id is:\", type(issue_id), issue_id)\n",
    "                #print (\"duplicate_id is:\", type(duplicate_id), duplicate_id)\n",
    "                \n",
    "                if pd.isnull(duplicate_id):\n",
    "                    continue\n",
    "\n",
    "                # Get descriptions of the bugs\n",
    "                description1 = get_bug_description(issue_id, bug_reports_file)\n",
    "                description2 = get_bug_description(duplicate_id, bug_reports_file)\n",
    "                \n",
    "                #print(\"description1 is:\", description1)\n",
    "                #print(\"description2 is:\", description2)\n",
    "\n",
    "                # if one of the descriptions is None, skip the comparison\n",
    "                if description1 is None or description2 is None:\n",
    "                    print(\"One of the descriptions is not found in the dataset. Skipping the comparison.\")\n",
    "                    continue\n",
    "\n",
    "                # Preprocess bug descriptions\n",
    "                preprocessed_desc1 = preprocess_bug_description(description1)\n",
    "                preprocessed_desc2 = preprocess_bug_description(description2)\n",
    "\n",
    "                # Compute TF-IDF similarity between bug descriptions\n",
    "                similarity = tfidf_similarity(preprocessed_desc1, preprocessed_desc2)\n",
    "\n",
    "                # Insert the TF-IDF similarity into the 4th column\n",
    "                pairs_data.loc[index, 'tfidf_similarity'] = similarity\n",
    "\n",
    "                #print the number of iterations\n",
    "                print(\"Iterations:\", index)\n",
    "\n",
    "            # Write the updated DataFrame with TF-IDF similarity into the existing CSV file\n",
    "            pairs_data.to_csv(os.path.join(target_dir, file_name), index=False)\n",
    "            print(\"Updated file saved:\", file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
