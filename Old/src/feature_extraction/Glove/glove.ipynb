{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n",
      "[ 4.2141e-01  2.0467e-02  1.2666e-01  3.9762e-01 -1.1016e-01 -3.5956e-02\n",
      " -4.7214e-01 -1.3916e-01  5.6812e-01 -3.4969e-01 -9.3232e-02 -1.7035e-01\n",
      " -3.8677e-01 -1.6811e-01 -1.0157e-01 -2.6612e-01  4.8094e-02 -4.6771e-01\n",
      " -6.0725e-01  4.0952e-01  3.1771e-01  5.0098e-01  6.6368e-01 -1.1827e-01\n",
      " -7.4267e-01 -1.0472e-01 -6.4353e-01 -4.4023e-01 -3.9101e-01  3.5694e-01\n",
      " -9.3489e-01  4.8317e-01  1.5223e-01  7.9339e-02 -2.5111e-01  3.9968e-01\n",
      " -1.7982e-01 -2.8874e-01 -1.0891e-01  3.8821e-01 -2.3147e-01 -5.0337e-01\n",
      " -2.5231e-01 -2.2184e-02 -2.7874e-01 -2.4193e-01  5.7466e-02 -5.3955e-01\n",
      " -3.4875e-02 -4.0482e-01 -3.8067e-02 -4.2337e-01  4.2861e-01  3.5166e-01\n",
      " -1.8165e-01 -3.1131e-01 -5.3276e-01 -5.0954e-02  6.6779e-01 -4.0077e-01\n",
      "  2.1403e-01 -2.9861e-01 -3.6637e-01  2.8489e-01 -3.7663e-01  5.9604e-02\n",
      " -3.1795e-01  2.5463e-01 -2.2185e-01  2.3032e-01 -1.2302e-01  2.4175e-01\n",
      " -1.0706e-01 -8.6599e-02 -3.7363e-02 -1.0403e-01  2.4492e-01 -8.4063e-01\n",
      " -1.5350e-01 -1.9363e-01 -1.8541e-02  1.0938e-01 -2.9402e-01 -1.1271e-01\n",
      " -3.8886e-01 -4.2836e-01 -4.4860e-01 -2.4651e-01 -9.4971e-02 -6.3275e-01\n",
      "  2.0591e-01 -7.7712e-01 -2.3888e-01 -7.9994e-01 -3.6994e-01  3.7863e-01\n",
      "  2.7856e-01 -1.0061e-01  6.4728e-02  9.1214e-02  2.4322e-01  3.9319e-01\n",
      "  2.7138e-01 -6.9390e-01 -3.7603e-01  1.9322e-01 -2.8888e-01 -1.3833e-02\n",
      " -2.0092e-01  2.0651e-01  1.1443e+00  2.0413e-01  7.7503e-02  3.6868e-01\n",
      "  2.6764e-01 -1.9205e-01  1.2437e-01  7.2540e-01 -4.0392e-01  2.0171e-01\n",
      "  2.7611e-02 -7.0727e-01  7.3353e-01 -2.8918e-01 -7.6865e-02  1.6481e-01\n",
      "  4.7930e-01  1.0438e+00 -1.2671e-02  2.1650e-01 -5.4563e-01  7.4603e-01\n",
      "  5.0535e-02  4.3028e-01  2.8583e-01 -2.2623e-01 -1.0048e-01  2.1873e-02\n",
      " -1.5193e-02 -3.6967e-01 -1.2580e-02 -3.3953e-02 -8.7644e-02  6.7809e-02\n",
      "  7.5793e-02  7.7514e-01  3.6431e-01 -3.1494e-01  4.4823e-01 -4.9692e-01\n",
      " -3.9522e-01  1.7200e-01  3.2744e-01  2.8070e-01 -2.2451e-01  1.6309e-02\n",
      " -4.9604e-01 -7.0684e-02  4.4588e-01  6.9836e-01  5.7786e-01 -8.6133e-02\n",
      "  8.8500e-02 -1.3028e-01 -4.7819e-01 -5.6810e-01 -3.5058e-01  4.5372e-01\n",
      " -7.7019e-02 -3.9147e-01 -6.2599e-03 -8.8470e-03 -5.5888e-01 -2.7865e-01\n",
      "  4.5821e-01  4.0499e-02  9.6597e-02  7.9329e-01 -8.1883e-03 -2.2361e-01\n",
      "  1.3949e-01  6.3997e-02 -4.8140e-02 -8.9970e-01  3.2938e-01 -7.3243e-01\n",
      "  4.9520e-01  4.3429e-01  3.9592e-01 -3.6047e-01 -4.4325e-01  1.1874e+00\n",
      " -1.4529e-01 -2.4614e-01  1.6348e-01  2.4299e-01 -8.6866e-02 -3.1420e-01\n",
      " -1.0316e-01  4.4774e-01  1.2476e-01  2.9402e-01  5.6585e-02 -8.1334e-03\n",
      "  4.1448e-01  7.8065e-02  4.2369e-01  5.9514e-01 -1.8196e-01 -1.1808e-01\n",
      " -1.6229e-01 -3.7044e-01 -4.5505e-01  2.3213e-01 -1.8806e-01 -5.7701e-02\n",
      "  3.5678e-01 -2.9694e-01  4.0711e-01  2.9314e-01  5.0997e-01 -4.9060e-01\n",
      " -3.8442e-02  2.7699e-01 -1.7814e-01  5.6196e-01 -2.5775e-01  1.6302e-01\n",
      " -1.2892e-01  1.8511e-01  4.4475e-02 -5.0004e-02  3.4030e-03  7.2436e-01\n",
      "  7.2849e-01 -5.0832e-02  6.3507e-01 -5.1974e-01 -1.8575e-02 -4.0821e-02\n",
      " -6.5155e-02 -4.7370e-01  3.1050e-02 -2.9190e-01 -1.0685e+00  1.9157e-01\n",
      "  3.5104e-01  6.5448e-01  9.4602e-02 -7.4953e-01  2.7771e-01  8.5203e-01\n",
      " -1.3938e-01 -2.6958e-03  7.5905e-01  1.5250e-01 -1.8057e-01  3.5792e-01\n",
      "  2.2094e-01 -2.6224e-03  2.4357e-01 -4.4449e-02  2.4307e-02 -1.8554e-01\n",
      "  5.4730e-01  6.7562e-02 -1.7508e-01 -4.9670e-01  1.9100e-01 -1.2052e-01\n",
      "  5.6214e-04 -4.2702e-02  8.3795e-02  4.1980e-01  1.4462e-01  1.4566e-01\n",
      " -3.3083e-01 -2.5936e-01 -5.8499e-01  8.2745e-02 -4.9894e-01 -2.4473e-01\n",
      " -3.1759e-01 -6.2230e-01 -4.1370e-01  1.0231e-01  5.6253e-01 -4.1108e-01\n",
      "  1.5782e-01  9.3600e-02 -6.6787e-02 -6.5050e-01  4.3919e-01 -7.7270e-02\n",
      " -1.0359e-01  2.0172e-01 -6.4019e-01  9.3869e-02  2.3952e-01  3.0140e-01]\n",
      "400000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('compute', 1.0),\n",
       " ('calculate', 0.65178025),\n",
       " ('computed', 0.5740565),\n",
       " ('computation', 0.5546042),\n",
       " ('computes', 0.53557724),\n",
       " ('algorithm', 0.535531),\n",
       " ('formula_1', 0.5304878),\n",
       " ('nodes', 0.5243916),\n",
       " ('formula_3', 0.5207261),\n",
       " ('formula_4', 0.5156089)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "GLOVE_DIR ='..//glove.6B'\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'),encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "print(embeddings_index['banana'])\n",
    "\n",
    "\n",
    "# ## Let's find the top 7 words that are closest to 'compute'\n",
    "\n",
    "u = embeddings_index['compute']\n",
    "norm_u = np.linalg.norm(u)\n",
    "similarity = []\n",
    "\n",
    "for word in embeddings_index.keys():\n",
    "    v = embeddings_index[word]\n",
    "    cosine = np.dot(u, v)/norm_u/np.linalg.norm(v)\n",
    "    similarity.append((word, cosine))\n",
    "print(len(similarity))\n",
    "\n",
    "sorted(similarity, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7847285),\n",
       " ('king', 0.66353697),\n",
       " ('ii', 0.51230603),\n",
       " ('majesty', 0.50936943),\n",
       " ('monarch', 0.4966937),\n",
       " ('prince', 0.4964633),\n",
       " ('royal', 0.48112637)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = embeddings_index['queen'] - embeddings_index['woman'] + embeddings_index['man']\n",
    "norm_out = np.linalg.norm(output)\n",
    "\n",
    "similarity = []\n",
    "for word in embeddings_index.keys():\n",
    "    v = embeddings_index[word]\n",
    "    cosine = np.dot(output, v)/norm_out/np.linalg.norm(v)\n",
    "    similarity.append((word, cosine))\n",
    "\n",
    "\n",
    "print(len(similarity))\n",
    "\n",
    "sorted(similarity, key=lambda x: x[1], reverse=True)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
