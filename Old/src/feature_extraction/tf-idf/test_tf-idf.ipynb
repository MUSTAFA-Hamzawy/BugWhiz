{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "directories = [\n",
    "    (\"..\\\\new_dataset\\\\eclipse\"),\n",
    "    #(\"..\\\\new_dataset\\\\firefox\", \"..\\\\BOW_dataset\\\\firefox\"),\n",
    "    #(\"..\\\\new_dataset\\\\netbeans\", \"..\\\\BOW_dataset\\\\netbeans\"),\n",
    "    #(\"..\\\\new_dataset\\\\openoffice\", \"..\\\\BOW_dataset\\\\openoffice\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess bug description text\n",
    "def preprocess_bug_description(description):\n",
    "\n",
    "    # convert description to string\n",
    "    description = str(description)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    description = description.lower()\n",
    "\n",
    "    # Remove punctuation and special characters\n",
    "    description = re.sub(r'[^a-zA-Z0-9\\s]', '', description)\n",
    "\n",
    "    # Remove numbers\n",
    "    description = re.sub(r'\\b\\d+\\b', '', description)\n",
    "\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Bug Reports\n",
    "def preprocess_bug_reports(bug_reports):\n",
    "    preprocessed_reports = []\n",
    "    for report in bug_reports:\n",
    "        # Implement your preprocessing steps here\n",
    "        preprocessed_report = preprocess_bug_description(report)\n",
    "        preprocessed_reports.append(preprocessed_report)\n",
    "    return preprocessed_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tfidf_similarity(issue_desc, duplicate_desc, tfidf_vectorizer):\n",
    "    # Transform bug descriptions into TF-IDF vectors\n",
    "    tfidf_issue = tfidf_vectorizer.transform([issue_desc])\n",
    "    tfidf_duplicate = tfidf_vectorizer.transform([duplicate_desc])\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(tfidf_issue, tfidf_duplicate)[0][0]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get bug descriptions based on bug IDs\n",
    "def get_bug_description(bug_id, file_data):    \n",
    "    \n",
    "    return file_data[file_data['bug_id'] == bug_id]['description'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "def train_model(train_data, bug_reports_file):\n",
    "    # Function to split duplicates based on ;\n",
    "    def split_and_join(duplicates):\n",
    "        return duplicates.split(';')\n",
    "\n",
    "    # Apply the function to split duplicates and store them in a new variable\n",
    "    train_data['duplicate'] = train_data['duplicate'].apply(split_and_join)\n",
    "\n",
    "    # print each issue_id and its duplicates\n",
    "    for index, row in train_data.iterrows():\n",
    "        print(row['issue_id'], row['duplicate'])\n",
    "    \n",
    "    # Fit the TF-IDF vectorizer on the training data\n",
    "    train_descriptions = [get_bug_description(issue_id, bug_reports_file) for issue_id in train_data['issue_id']]\n",
    "    tfidf_vectorizer.fit(train_descriptions)\n",
    "\n",
    "    print(\"1: \", preprocess_bug_description(get_bug_description(row['issue_id'], bug_reports_file)))\n",
    "    print(\"12154: \",row['duplicate'] )\n",
    "    \n",
    "    print (\"111: \", get_bug_description(row['duplicate'], bug_reports_file))\n",
    "    print(\"2: \", preprocess_bug_description(get_bug_description(row['duplicate'], bug_reports_file)))\n",
    "\n",
    "    # Compute TF-IDF similarity for training pairs\n",
    "    train_data['tfidf_similarity'] = train_data.apply(lambda row: calculate_tfidf_similarity(\n",
    "        preprocess_bug_description(get_bug_description(row['issue_id'], bug_reports_file)),\n",
    "        preprocess_bug_description(get_bug_description(row['duplicate'], bug_reports_file)),\n",
    "        tfidf_vectorizer\n",
    "    ), axis=1)\n",
    "\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_similarity(bug1, bug2):\n",
    "\n",
    "    # Apply TF-IDF to bug reports\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([bug1, bug2])\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_data, bug_reports_file):\n",
    "    # Define a lambda function to compute TF-IDF similarity for each pair of bug reports\n",
    "    compute_similarity = lambda row: tfidf_similarity(get_bug_description(row['issue_id'], bug_reports_file), \n",
    "                                                      get_bug_description(row['duplicate_id'], bug_reports_file))\n",
    "\n",
    "    # Apply the lambda function to each row in the test data DataFrame to compute TF-IDF similarity\n",
    "    test_data['tfidf_similarity'] = test_data.apply(compute_similarity, axis=1)\n",
    "\n",
    "    return test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs file loaded: eclipse_small_pairs.csv\n",
      "Original bug reports file loaded: eclipse_small_new.csv\n",
      "214429 ['214074']\n",
      "214577 ['214074']\n",
      "214297 ['214074']\n",
      "214328 ['214074']\n",
      "214988 ['214989']\n",
      "214855 ['214074']\n",
      "214713 ['214074']\n",
      "214748 ['214074']\n",
      "215052 ['214074']\n",
      "214505 ['214074']\n",
      "214089 ['214080']\n",
      "214173 ['214074']\n",
      "214755 ['214744']\n",
      "214876 ['214074']\n",
      "214197 ['214074']\n",
      "214551 ['214074']\n",
      "214837 ['214074']\n",
      "215022 ['214074']\n",
      "214687 ['214074']\n",
      "214524 ['214074']\n",
      "214118 ['214074']\n",
      "214930 ['214074']\n",
      "214209 ['214074']\n",
      "214576 ['214074']\n",
      "214289 ['214074']\n",
      "214097 ['214074']\n",
      "214691 ['214074']\n",
      "215018 ['214074']\n",
      "214309 ['214074']\n",
      "214633 ['214074']\n",
      "214563 ['214074']\n",
      "214669 ['214074']\n",
      "214772 ['214074']\n",
      "214445 ['214451']\n",
      "214631 ['214074']\n",
      "214296 ['214074']\n",
      "214500 ['214074']\n",
      "214632 ['214074']\n",
      "214135 ['214074']\n",
      "214580 ['214578']\n",
      "214235 ['214074']\n",
      "214366 ['214074']\n",
      "214836 ['214074']\n",
      "214153 ['214074']\n",
      "214219 ['214074']\n",
      "214976 ['214074']\n",
      "214764 ['214074']\n",
      "214862 ['214759']\n",
      "214897 ['214074']\n",
      "214806 ['214074']\n",
      "214181 ['214074']\n",
      "214902 ['214074']\n",
      "214554 ['214074']\n",
      "214634 ['214074']\n",
      "214759 ['214074']\n",
      "214326 ['214074']\n",
      "214254 ['214074']\n",
      "214932 ['214074']\n",
      "214247 ['214074']\n",
      "214615 ['214074']\n",
      "214301 ['214611']\n",
      "214800 ['214074']\n",
      "214341 ['214074']\n",
      "214370 ['214074']\n",
      "215056 ['214074']\n",
      "214347 ['214074']\n",
      "214848 ['214074']\n",
      "214192 ['214074']\n",
      "214140 ['214074']\n",
      "214068 ['214074']\n",
      "214935 ['214934', '214936']\n",
      "214542 ['214074']\n",
      "214086 ['214074']\n",
      "214496 ['214074']\n",
      "214645 ['214074']\n",
      "214865 ['214074']\n",
      "214762 ['214074']\n",
      "214539 ['214074']\n",
      "214997 ['214074']\n",
      "214384 ['214074']\n",
      "214904 ['214074']\n",
      "215003 ['214074']\n",
      "214523 ['214074']\n",
      "214673 ['214074']\n",
      "214374 ['214074']\n",
      "214484 ['214074']\n",
      "214276 ['214074']\n",
      "214934 ['214936']\n",
      "214102 ['214074']\n",
      "214999 ['214074']\n",
      "214260 ['214074']\n",
      "214677 ['214074']\n",
      "214074 ['214073']\n",
      "214071 ['214074']\n",
      "214466 ['214452']\n",
      "214629 ['214074']\n",
      "214444 ['214074']\n",
      "214540 ['214074']\n",
      "214788 ['214074']\n",
      "214246 ['214074']\n",
      "214320 ['214074']\n",
      "214979 ['214074']\n",
      "214850 ['214074']\n",
      "214337 ['214074']\n",
      "215000 ['214074']\n",
      "214747 ['214074']\n",
      "214690 ['214074']\n",
      "214879 ['214074']\n",
      "214668 ['214074']\n",
      "214783 ['214074']\n",
      "214571 ['214074']\n",
      "214510 ['214074']\n",
      "214443 ['214074']\n",
      "214787 ['214074']\n",
      "214929 ['214074']\n",
      "215017 ['214074']\n",
      "215039 ['214074']\n",
      "214400 ['214074']\n",
      "214342 ['214074']\n",
      "214474 ['214074']\n",
      "214069 ['214068']\n",
      "214801 ['214074']\n",
      "214261 ['214074']\n",
      "214177 ['214074']\n",
      "214369 ['214074']\n",
      "214991 ['214988', '214989', '214990']\n",
      "214903 ['214074']\n",
      "214372 ['214303', '214301', '214304', '214305', '214611', '214306']\n",
      "214175 ['214074']\n",
      "214087 ['214074']\n",
      "215019 ['214074']\n",
      "214270 ['214216']\n",
      "214487 ['214074']\n",
      "214257 ['214074']\n",
      "214780 ['214074']\n",
      "215040 ['214988', '214990', '214991', '214989']\n",
      "214116 ['214074']\n",
      "214635 ['214074']\n",
      "214623 ['214074']\n",
      "214538 ['214074']\n",
      "214689 ['214074']\n",
      "214970 ['214074']\n",
      "214224 ['214074']\n",
      "214076 ['214074']\n",
      "214274 ['214074']\n",
      "215005 ['214074']\n",
      "215002 ['214074']\n",
      "214078 ['214074']\n",
      "214421 ['214074']\n",
      "214834 ['214074']\n",
      "214306 ['214303', '214304', '214305', '214611', '214301']\n",
      "214770 ['214074']\n",
      "214220 ['214074']\n",
      "214230 ['214074']\n",
      "214411 ['214074']\n",
      "215016 ['214074']\n",
      "214154 ['214074']\n",
      "214674 ['214074']\n",
      "1:  version eclipse persistence services version build buildnumber test model name sessionsxmltestmodel model description this model tests the sessions xml feature version eclipse persistence services version build buildnumber test suite name xml schema tests suite description version eclipse persistence services version build buildnumber test name sessionsxmlschemaincorrecttagvaluestest test description test sessions xml schema with incorrect tag values failure test time total time result error local exception stack exception eclipselink0 eclipse persistence services version build buildnumber orgeclipsepersistencetestingframeworktesterrorexception exception description fatal error occured internal exception javalangclasscastexception orgeclipsepersistenceplatformxmlxmlplatformexception at orgeclipsepersistencetestingframeworktestcaseexecutetestcasejava162 at orgeclipsepersistencetestingframeworktestexecutorexecutetestexecutorjava244 at orgeclipsepersistencetestingframeworktestsuiteexecutetestsuitejava72 at orgeclipsepersistencetestingframeworktestexecutorexecutetestexecutorjava244 at orgeclipsepersistencetestingframeworktestmodelexecutetestmodeljava205 at orgeclipsepersistencetestingframeworktestexecutorexecutetestexecutorjava244 at orgeclipsepersistencetestingframeworktestmodelexecutetestmodeljava205 at orgeclipsepersistencetestingframeworktestexecutorexecutetestexecutorjava244 at orgeclipsepersistencetestingframeworktestexecutorruntesttestexecutorjava660 at orgeclipsepersistencetestingframeworkuisynchronizedtestexecutorrunsynchronizedtestexecutorjava58 caused by javalangclasscastexception orgeclipsepersistenceplatformxmlxmlplatformexception at orgeclipsepersistencetestingtestssessionsxmlsessionsxmlschemaincorrecttagvaluestestverifysessionsxmlschemaincorrecttagvaluestestjava45 at orgeclipsepersistencetestingframeworktestcaseexecutetestcasejava153 more results of test suite xml schema tests errors warnings problems errors fatal errors passed setup warnings setup failures total time total tests results of test model sessionsxmltestmodel errors warnings problems errors fatal errors passed setup warnings setup failures total time total tests the problem is in xmlschemaincorrecttagvaluesxml file eclipselinkplatformclassdbplatformeclipselinkplatformclass should be changed to platformclassdbplatformplatformclass\n",
      "12154:  ['214074']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "('Lengths must match to compare', (878,), (1,))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [103]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m train_test_split(pairs_data, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbug_reports_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m test_data \u001b[38;5;241m=\u001b[39m test_model(test_data, bug_reports_file)\n",
      "Input \u001b[1;32mIn [100]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_data, bug_reports_file)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1: \u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocess_bug_description(get_bug_description(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue_id\u001b[39m\u001b[38;5;124m'\u001b[39m], bug_reports_file)))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m12154: \u001b[39m\u001b[38;5;124m\"\u001b[39m,row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicate\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m111: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mget_bug_description\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mduplicate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbug_reports_file\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2: \u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocess_bug_description(get_bug_description(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicate\u001b[39m\u001b[38;5;124m'\u001b[39m], bug_reports_file)))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Compute TF-IDF similarity for training pairs\u001b[39;00m\n",
      "Input \u001b[1;32mIn [99]\u001b[0m, in \u001b[0;36mget_bug_description\u001b[1;34m(bug_id, file_data)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bug_description\u001b[39m(bug_id, file_data):    \n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file_data[\u001b[43mfile_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbug_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbug_id\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:42\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6240\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   6242\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 6243\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:264\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# TODO: make this treatment consistent across ops and classes.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m#  We are not catching all listlikes here (e.g. frozenset, tuple)\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m#  The ambiguous case is object-dtype.  See GH#27803\u001b[39;00m\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lvalues) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rvalues):\n\u001b[1;32m--> 264\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths must match to compare\u001b[39m\u001b[38;5;124m\"\u001b[39m, lvalues\u001b[38;5;241m.\u001b[39mshape, rvalues\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    266\u001b[0m         )\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_extension_dispatch(lvalues, rvalues) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m    269\u001b[0m     (\u001b[38;5;28misinstance\u001b[39m(rvalues, (Timedelta, BaseOffset, Timestamp)) \u001b[38;5;129;01mor\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m NaT)\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    271\u001b[0m ):\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# Call the method on lvalues\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m op(lvalues, rvalues)\n",
      "\u001b[1;31mValueError\u001b[0m: ('Lengths must match to compare', (878,), (1,))"
     ]
    }
   ],
   "source": [
    "# Iterate over each directory\n",
    "for source_dir in directories:\n",
    "    # Iterate over each file in the directory\n",
    "    for file_name in os.listdir(source_dir):\n",
    "        # Check if the file is a CSV file and contains \"_new_similarity\" in its name\n",
    "        if file_name.endswith(\".csv\") and \"_pairs\" in file_name:\n",
    "            # Load the CSV file with similarity data\n",
    "            pairs_data = pd.read_csv(os.path.join(source_dir, file_name))\n",
    "            print(\"Pairs file loaded:\", file_name)\n",
    "\n",
    "            # Load the original bug reports file\n",
    "            original_file_name = file_name.replace(\"_pairs.csv\", \"_new.csv\")\n",
    "            bug_reports_file = pd.read_csv(os.path.join(source_dir, original_file_name))\n",
    "            print(\"Original bug reports file loaded:\", original_file_name)\n",
    "\n",
    "            # Split the data into training and testing sets (80% for training, 20% for testing)\n",
    "            train_data, test_data = train_test_split(pairs_data, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Train the model\n",
    "            train_data = train_model(train_data, bug_reports_file)\n",
    "\n",
    "            # Test the model\n",
    "            test_data = test_model(test_data, bug_reports_file)\n",
    "\n",
    "            # Print the updated DataFrame with TF-IDF similarity scores\n",
    "            print(\"Updated training data:\", train_data.head())\n",
    "            print(\"Updated testing data:\", test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
