{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOUh0894Z2QM",
    "outputId": "8a05336a-818f-4882-b110-624020d0333e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in the file: 333668\n"
     ]
    }
   ],
   "source": [
    "file_path = 'merged_file.csv'\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Use a loop to iterate over each line in the file\n",
    "    line_count = sum(1 for line in file)\n",
    "\n",
    "print(\"Number of lines in the original file:\", line_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the CSV file: ['Bug ID', 'Product', 'Component', 'Assignee', 'Status', 'Resolution', 'Summary', 'Changed']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = 'merged_file.csv'\n",
    "\n",
    "# Open the CSV file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Create a CSV reader object\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # Read the first row of the CSV file\n",
    "    column_names = next(csv_reader)\n",
    "\n",
    "print(\"Column names in the CSV file:\", column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements in the 'Assignee' column:\n",
      "['UNCONFIRMED' 'NEW' 'ASSIGNED' 'REOPENED' 'RESOLVED' 'VERIFIED' 'CLOSED']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'merged_file.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Get the unique elements in the \"Assignee\" column\n",
    "unique_assignees = df['Status'].unique()\n",
    "\n",
    "print(\"Unique elements in the 'Status' column:\")\n",
    "print(unique_assignees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements in the 'Resolution' column:\n",
      "[' ---' 'FIXED' 'WONTFIX' 'INVALID' 'NOT_ECLIPSE' 'WORKSFORME' 'DUPLICATE'\n",
      " 'MOVED']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'merged_file.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Get the unique elements in the \"Assignee\" column\n",
    "unique_assignees = df['Resolution'].unique()\n",
    "\n",
    "print(\"Unique elements in the 'Resolution' column:\")\n",
    "print(unique_assignees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with Resolution \"Duplicate\"\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'merged_file.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Filter out rows with 'Duplicate' in the 'Status' column\n",
    "df = df[df['Resolution'] != 'DUPLICATE']\n",
    "\n",
    "# Write the filtered DataFrame back to a CSV file\n",
    "df.to_csv('filtered_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines after filtering: 305093\n"
     ]
    }
   ],
   "source": [
    "file_path = 'filtered_file.csv'\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Use a loop to iterate over each line in the file\n",
    "    line_count = sum(1 for line in file)\n",
    "\n",
    "print(\"Number of lines after filtering:\", line_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique elements in the 'Resolution' column:\n",
      "['UNCONFIRMED' 'NEW' 'ASSIGNED' 'REOPENED' 'RESOLVED' 'VERIFIED' 'CLOSED']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'merged_file.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Get the unique elements in the \"Assignee\" column\n",
    "unique_assignees = df['Status'].unique()\n",
    "\n",
    "print(\"Unique elements in the 'Resolution' column:\")\n",
    "print(unique_assignees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the CSV file: ['Bug ID', 'Product', 'Component', 'Assignee', 'Status', 'Resolution', 'Summary', 'Changed']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = 'filtered_file.csv'\n",
    "\n",
    "# Open the CSV file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Create a CSV reader object\n",
    "    csv_reader = csv.reader(file)\n",
    "    \n",
    "    # Read the first row of the CSV file\n",
    "    column_names = next(csv_reader)\n",
    "\n",
    "print(\"Column names in the CSV file:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of words in 'summary' column: 0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def get_min_words_in_summary(csv_file_path):\n",
    "  \"\"\"\n",
    "  This function takes a CSV file path and returns the minimum number of words \n",
    "  found in any element of the \"summary\" column.\n",
    "\n",
    "  Args:\n",
    "      csv_file_path (str): Path to the CSV file.\n",
    "\n",
    "  Returns:\n",
    "      int: The minimum number of words in the \"summary\" column.\n",
    "  \"\"\"\n",
    "  min_words = float('inf')  # Initialize with positive infinity\n",
    "\n",
    "  with open(csv_file_path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "\n",
    "    # Skip header row (optional)\n",
    "    next(reader, None)\n",
    "\n",
    "    for row in reader:\n",
    "      summary_text = row[6]  # Assuming you know the index\n",
    "      word_count = len(summary_text.split())  # Split by whitespace to count words\n",
    "\n",
    "      if word_count < min_words:\n",
    "        min_words = word_count\n",
    "\n",
    "  return min_words\n",
    "\n",
    "# Replace with the actual column index and your CSV file path\n",
    "summary_column_index = 2  # Assuming \"summary\" is the 3rd column (index starts from 0)\n",
    "csv_file_path = \"filtered_file.csv\"\n",
    "\n",
    "min_word_count = get_min_words_in_summary(csv_file_path)\n",
    "\n",
    "print(f\"Minimum number of words in 'summary' column: {min_word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file processed. Result saved in: filtered_file_2.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def remove_short_summary_columns(input_file, output_file, word_threshold=10):\n",
    "  \"\"\"\n",
    "  This function removes columns with less than the specified word threshold \n",
    "  in the 'Summary' column from a CSV file, cleans special characters, newlines, \n",
    "  removes hyperlinks, and saves the result in another file.\n",
    "\n",
    "  Args:\n",
    "      input_file (str): Path to the input CSV file.\n",
    "      output_file (str): Path to the output CSV file.\n",
    "      word_threshold (int, optional): Minimum number of words allowed in the 'Summary' column. Defaults to 10.\n",
    "  \"\"\"\n",
    "  with open(input_file, 'r', newline='') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # Read the header row\n",
    "    header_row = next(reader)\n",
    "    # Identify the index of the 'Summary' column\n",
    "    summary_index = header_row.index('Summary')\n",
    "\n",
    "    # Write the header row to the output file\n",
    "    writer.writerow(header_row)\n",
    "\n",
    "    # Define regular expressions for special characters, newlines, and hyperlinks\n",
    "    special_char_pattern = r\"[^\\w\\s]\"\n",
    "    url_pattern = r\"(http|https)?://[^\\s]+?\"  # Matches URLs with optional protocol (http/https)\n",
    "\n",
    "    # Process each data row\n",
    "    for row in reader:\n",
    "      # Clean the 'Summary' column element\n",
    "      clean_summary = re.sub(special_char_pattern, \"\", row[summary_index])\n",
    "      clean_summary = clean_summary.replace('\\n', ' ')  # Replace newline with space\n",
    "      clean_summary = re.sub(url_pattern, \"\", clean_summary)  # Remove hyperlinks\n",
    "\n",
    "      # Count words in the cleaned 'Summary' column\n",
    "      word_count = len(clean_summary.split())\n",
    "\n",
    "      # Include row only if word count meets the threshold\n",
    "      if word_count >= word_threshold:\n",
    "        row[summary_index] = clean_summary  # Update row with cleaned summary\n",
    "        writer.writerow(row)\n",
    "\n",
    "# Example usage\n",
    "input_file = 'filtered_file.csv'\n",
    "output_file = 'filtered_file_2.csv'\n",
    "remove_short_summary_columns(input_file, output_file)\n",
    "\n",
    "print(f\"CSV file processed. Result saved in: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of words in 'summary' column: 10\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def get_min_words_in_summary(csv_file_path):\n",
    "  \"\"\"\n",
    "  This function takes a CSV file path and returns the minimum number of words \n",
    "  found in any element of the \"summary\" column.\n",
    "\n",
    "  Args:\n",
    "      csv_file_path (str): Path to the CSV file.\n",
    "\n",
    "  Returns:\n",
    "      int: The minimum number of words in the \"summary\" column.\n",
    "  \"\"\"\n",
    "  min_words = float('inf')  # Initialize with positive infinity\n",
    "\n",
    "  with open(csv_file_path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "\n",
    "    # Skip header row (optional)\n",
    "    next(reader, None)\n",
    "\n",
    "    for row in reader:\n",
    "      summary_text = row[6]  # Assuming you know the index\n",
    "      word_count = len(summary_text.split())  # Split by whitespace to count words\n",
    "\n",
    "      if word_count < min_words:\n",
    "        min_words = word_count\n",
    "\n",
    "  return min_words\n",
    "\n",
    "# Replace with the actual column index and your CSV file path\n",
    "summary_column_index = 2  # Assuming \"summary\" is the 3rd column (index starts from 0)\n",
    "csv_file_path = \"filtered_file_2.csv\"\n",
    "\n",
    "min_word_count = get_min_words_in_summary(csv_file_path)\n",
    "\n",
    "print(f\"Minimum number of words in 'summary' column: {min_word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines after filtering: 86655\n"
     ]
    }
   ],
   "source": [
    "file_path = 'filtered_file_2.csv'\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r') as file:\n",
    "    # Use a loop to iterate over each line in the file\n",
    "    line_count = sum(1 for line in file)\n",
    "\n",
    "print(\"Number of lines after filtering:\", line_count)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
