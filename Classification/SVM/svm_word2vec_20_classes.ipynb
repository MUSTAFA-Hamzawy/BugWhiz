{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1owhJo-7c_s"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WfJvhCiZ6gft"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd  # Pandas for data manipulation and analysis\n",
        "from sklearn.preprocessing import LabelEncoder  # LabelEncoder for encoding categorical target labels\n",
        "from sklearn.svm import SVC  # SVC (Support Vector Classifier) for SVM classification\n",
        "from sklearn.metrics import accuracy_score  # Metrics for evaluating model performance\n",
        "from sklearn.model_selection import StratifiedShuffleSplit  # StratifiedShuffleSplit for train-test splitting\n",
        "import joblib  # Joblib for saving and loading models\n",
        "from gensim.models import Word2Vec  # Import Word2Vec from gensim for word embeddings\n",
        "import numpy as np  # for numerical operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIjQw4jv7jlz"
      },
      "source": [
        "**Load The Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgkV2Cg3gIk5",
        "outputId": "61f3fe21-1a4e-477d-a9c8-7bfa11817cd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access files and save outputs\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9bLUtRI77py8"
      },
      "outputs": [],
      "source": [
        "# Specify the file path in Google Drive and load the dataset after preprocessing\n",
        "file_path = '/content/drive/My Drive/dataset_after_preprocessing.csv'\n",
        "dataset = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEpGHhq8DxpT"
      },
      "source": [
        "**Show the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3slWtLr_oMVi",
        "outputId": "5353cdda-2eca-401c-d960-3277ac26e5a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ee217ced-ac49-4f12-8cb6-76e1c7966979\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary_Stemmed</th>\n",
              "      <th>processed_summary</th>\n",
              "      <th>Assignee</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['scroll', 'scroll', 'mice', 'touchpad', 'etc'...</td>\n",
              "      <td>scroll scroll mice touchpad etc scroll</td>\n",
              "      <td>amit@chromium.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['add', 'check', 'item', 'download', 'panel', ...</td>\n",
              "      <td>add check item download panel browser test</td>\n",
              "      <td>achuith@chromium.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['useafterfre', 'navig', 'document', 'form', '...</td>\n",
              "      <td>useafterfre navig document form valid messag s...</td>\n",
              "      <td>tkent@chromium.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['add', 'address', 'properli', 'autofil', 'opt...</td>\n",
              "      <td>add address properli autofil option dialog box</td>\n",
              "      <td>sky@chromium.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['libxmlgyp', 'defin', 'libxmlstat', 'direct',...</td>\n",
              "      <td>libxmlgyp defin libxmlstat direct depend</td>\n",
              "      <td>wtc@chromium.org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117376</th>\n",
              "      <td>['updat', 'gleanj', 'dashboard', 'ignor', 'gle...</td>\n",
              "      <td>updat gleanj dashboard ignor glean sdk data vpn</td>\n",
              "      <td>brosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117377</th>\n",
              "      <td>['autocomplet', 'type', 'valid', 'valu', 'pass...</td>\n",
              "      <td>autocomplet type valid valu pass record</td>\n",
              "      <td>brosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117378</th>\n",
              "      <td>['intermitt', 'slow', 'see', 'ping', 'show', '...</td>\n",
              "      <td>intermitt slow see ping show debug ping viewer</td>\n",
              "      <td>brosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117379</th>\n",
              "      <td>['investig', 'string', 'metric', 'type', 'adeq...</td>\n",
              "      <td>investig string metric type adequ captur gfxad...</td>\n",
              "      <td>pmcmanis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117380</th>\n",
              "      <td>['remov', 'manual', 'page', 'load', 'event', '...</td>\n",
              "      <td>remov manual page load event glean debug ping ...</td>\n",
              "      <td>brosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>117381 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee217ced-ac49-4f12-8cb6-76e1c7966979')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee217ced-ac49-4f12-8cb6-76e1c7966979 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee217ced-ac49-4f12-8cb6-76e1c7966979');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4805af2c-2931-4f68-bca6-72512762b2bf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4805af2c-2931-4f68-bca6-72512762b2bf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4805af2c-2931-4f68-bca6-72512762b2bf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_72e28052-f483-483c-8ef9-ffec73e41d1b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_72e28052-f483-483c-8ef9-ffec73e41d1b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          Summary_Stemmed  \\\n",
              "0       ['scroll', 'scroll', 'mice', 'touchpad', 'etc'...   \n",
              "1       ['add', 'check', 'item', 'download', 'panel', ...   \n",
              "2       ['useafterfre', 'navig', 'document', 'form', '...   \n",
              "3       ['add', 'address', 'properli', 'autofil', 'opt...   \n",
              "4       ['libxmlgyp', 'defin', 'libxmlstat', 'direct',...   \n",
              "...                                                   ...   \n",
              "117376  ['updat', 'gleanj', 'dashboard', 'ignor', 'gle...   \n",
              "117377  ['autocomplet', 'type', 'valid', 'valu', 'pass...   \n",
              "117378  ['intermitt', 'slow', 'see', 'ping', 'show', '...   \n",
              "117379  ['investig', 'string', 'metric', 'type', 'adeq...   \n",
              "117380  ['remov', 'manual', 'page', 'load', 'event', '...   \n",
              "\n",
              "                                        processed_summary  \\\n",
              "0                  scroll scroll mice touchpad etc scroll   \n",
              "1              add check item download panel browser test   \n",
              "2       useafterfre navig document form valid messag s...   \n",
              "3          add address properli autofil option dialog box   \n",
              "4                libxmlgyp defin libxmlstat direct depend   \n",
              "...                                                   ...   \n",
              "117376    updat gleanj dashboard ignor glean sdk data vpn   \n",
              "117377            autocomplet type valid valu pass record   \n",
              "117378     intermitt slow see ping show debug ping viewer   \n",
              "117379  investig string metric type adequ captur gfxad...   \n",
              "117380  remov manual page load event glean debug ping ...   \n",
              "\n",
              "                    Assignee  \n",
              "0          amit@chromium.org  \n",
              "1       achuith@chromium.org  \n",
              "2         tkent@chromium.org  \n",
              "3           sky@chromium.org  \n",
              "4           wtc@chromium.org  \n",
              "...                      ...  \n",
              "117376                 brosa  \n",
              "117377                 brosa  \n",
              "117378                 brosa  \n",
              "117379              pmcmanis  \n",
              "117380                 brosa  \n",
              "\n",
              "[117381 rows x 3 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the DataFrame 'dataset'\n",
        "# This will print the first and last 5 rows of the DataFrame along with the column names and index\n",
        "# Useful for a quick overview of the data after processing\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKXnH87j8Hmb"
      },
      "source": [
        "**Encode the labels**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s_m3q3r18K1V"
      },
      "outputs": [],
      "source": [
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit the LabelEncoder to the 'Assignee' column and transform it to numeric labels\n",
        "# This step converts categorical labels in the 'Assignee' column to numeric labels,\n",
        "# which is necessary for training machine learning models.\n",
        "dataset['Assignee_Class'] = label_encoder.fit_transform(dataset['Assignee'])\n",
        "\n",
        "# The LabelEncoder in scikit-learn assigns numeric labels to the unique categories in alphabetical order\n",
        "# (or lexicographical order for strings).\n",
        "# This means that the first unique category in alphabetical order is labeled as 0, the second as 1, and so on.\n",
        "\n",
        "y = dataset['Assignee_Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train only on 20 classes of the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rNaVkOS1EDqg"
      },
      "outputs": [],
      "source": [
        "dataset= dataset[dataset['Assignee_Class']<20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oaY3fVPSEK3c"
      },
      "outputs": [],
      "source": [
        "y = dataset['Assignee_Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRiKymB2DxpU"
      },
      "source": [
        "**Display the number of unique values in each column of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFY1Micb98uu",
        "outputId": "9652291c-0b6a-47a4-9d79-53fedb000332"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Summary_Stemmed      2747\n",
              "processed_summary    2747\n",
              "Assignee               20\n",
              "Assignee_Class         20\n",
              "dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the number of unique values in each column of the dataset\n",
        "dataset.nunique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rcK7Qwm89P_"
      },
      "source": [
        "**Split the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OkGo3er2ikC",
        "outputId": "dac98f79-8dfe-4250-bcc7-eb74cd40eb50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2748, 4)\n",
            "Assignee_Class\n",
            "11    779\n",
            "0     641\n",
            "19    560\n",
            "1     251\n",
            "16    115\n",
            "13    113\n",
            "8      80\n",
            "5      42\n",
            "4      40\n",
            "7      31\n",
            "17     24\n",
            "18     15\n",
            "12     13\n",
            "15      9\n",
            "6       7\n",
            "3       7\n",
            "10      6\n",
            "14      5\n",
            "2       5\n",
            "9       5\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Print the shape of the dataset\n",
        "print(dataset.shape)\n",
        "# This line prints the shape of the dataset, which includes the number of rows and columns.\n",
        "# It helps to understand the dimensions of the dataset.\n",
        "\n",
        "# Print the class distribution of 'Assignee_Class'\n",
        "print(dataset['Assignee_Class'].value_counts())\n",
        "# This line prints the count of each unique value in the 'Assignee_Class' column.\n",
        "# It provides insight into the distribution of classes, which is useful for understanding class imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp77sEmvGa6e"
      },
      "source": [
        "**Convert input text into a list of words.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JpFS7j27H7jm"
      },
      "outputs": [],
      "source": [
        "def ensure_list_of_words(text):\n",
        "    \"\"\"\n",
        "    Converts input text into a list of words.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str or list): Input text to be converted. If a string, it will be split into a list of words.\n",
        "\n",
        "    Returns:\n",
        "    - list: List of words extracted from the input text.\n",
        "\n",
        "    Notes:\n",
        "    - If the input is already a list, it will be returned unchanged.\n",
        "    - Uses split() method to separate words based on whitespace.\n",
        "\n",
        "    Example:\n",
        "    >>> ensure_list_of_words(\"Hello world!\")\n",
        "    ['Hello', 'world!']\n",
        "    >>> ensure_list_of_words([\"Hello\", \"world!\"])\n",
        "    ['Hello', 'world!']\n",
        "    \"\"\"\n",
        "    if isinstance(text, str):\n",
        "        return text.split()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "19VoFfE5ILbQ",
        "outputId": "9684a089-5f3f-4751-da6c-816485968370"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-69c87a2a8ec4>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[\"Summary_Stemmed\"] = dataset[\"Summary_Stemmed\"].apply(ensure_list_of_words)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nPurpose:\\nThis line of code applies the ensure_list_of_words function to each element in the \\'Summary_Stemmed\\' column of the dataset.\\n\\nOperation:\\ndataset[\"Summary_Stemmed\"].apply(ensure_list_of_words): Uses the apply method to iterate over each element in the \\'Summary_Stemmed\\' column.\\nensure_list_of_words: The function ensure_list_of_words is called for each element. It ensures that each element (which is presumably a string or list) is converted into a list of words.\\n\\nEffect:\\nModifies the \\'Summary_Stemmed\\' column in dataset so that each entry is now represented as a list of words.\\n\\nExample:\\nIf dataset[\"Summary_Stemmed\"] originally contained strings like \"run running runner\", after applying ensure_list_of_words, it would be transformed into a list like [\"run\", \"running\", \"runner\"].\\n'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"Summary_Stemmed\"] = dataset[\"Summary_Stemmed\"].apply(ensure_list_of_words)\n",
        "\"\"\"\n",
        "Purpose:\n",
        "This line of code applies the ensure_list_of_words function to each element in the 'Summary_Stemmed' column of the dataset.\n",
        "\n",
        "Operation:\n",
        "dataset[\"Summary_Stemmed\"].apply(ensure_list_of_words): Uses the apply method to iterate over each element in the 'Summary_Stemmed' column.\n",
        "ensure_list_of_words: The function ensure_list_of_words is called for each element. It ensures that each element (which is presumably a string or list) is converted into a list of words.\n",
        "\n",
        "Effect:\n",
        "Modifies the 'Summary_Stemmed' column in dataset so that each entry is now represented as a list of words.\n",
        "\n",
        "Example:\n",
        "If dataset[\"Summary_Stemmed\"] originally contained strings like \"run running runner\", after applying ensure_list_of_words, it would be transformed into a list like [\"run\", \"running\", \"runner\"].\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng0KBd_rDxpY"
      },
      "source": [
        "**Initialize and train a Word2Vec model using the data from the 'Summary_Stemmed' column of the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "k76X56U8Gc5q",
        "outputId": "f266bad1-cb0b-433f-9bb6-87dbaaf12c2a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nPurpose:\\nThis code initializes and trains a Word2Vec model using the data from the \\'Summary_Stemmed\\' column of the dataset.\\n\\nParameters:\\nsentences: Input data for training, expected as a list where each element is a list of words (tokens) representing a sentence or document.\\nvector_size: Dimensionality of the word vectors produced by the model.\\nwindow: Maximum distance between the current and predicted word within a sentence. A larger window size considers more context words.\\nmin_count: Ignores all words with a total frequency lower than this value across the corpus. Helps in filtering out infrequent words.\\nworkers: Number of threads used for training the model, to speed up the training process.\\nepochs: Number of iterations (epochs) over the corpus during training, where each epoch processes the entire dataset once.\\n\\nTraining Process:\\nThe Word2Vec model (w2v_model) is trained on the tokenized sentences provided in dataset[\"Summary_Stemmed\"].\\nDuring training, the model learns to map words into a high-dimensional vector space such that words with similar contexts are closer in this space.\\n\\nOutput:\\nAfter training, w2v_model contains the learned word vectors that can be used to infer vectors for new words or sentences and perform similarity queries.\\n'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train a Word2Vec model on the 'Summary_Stemmed' column of the dataset\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=dataset[\"Summary_Stemmed\"],  # Input data: list of tokenized sentences or documents\n",
        "    vector_size=500,                       # Dimensionality of the word vectors\n",
        "    window=20,                             # Maximum distance between the current and predicted word within a sentence\n",
        "    min_count=2,                           # Ignore all words with total frequency lower than this\n",
        "    workers=4,                             # Number of threads to use for training\n",
        "    epochs=250                             # Number of iterations (epochs) over the corpus\n",
        ")\n",
        "\n",
        "\"\"\"\n",
        "Purpose:\n",
        "This code initializes and trains a Word2Vec model using the data from the 'Summary_Stemmed' column of the dataset.\n",
        "\n",
        "Parameters:\n",
        "sentences: Input data for training, expected as a list where each element is a list of words (tokens) representing a sentence or document.\n",
        "vector_size: Dimensionality of the word vectors produced by the model.\n",
        "window: Maximum distance between the current and predicted word within a sentence. A larger window size considers more context words.\n",
        "min_count: Ignores all words with a total frequency lower than this value across the corpus. Helps in filtering out infrequent words.\n",
        "workers: Number of threads used for training the model, to speed up the training process.\n",
        "epochs: Number of iterations (epochs) over the corpus during training, where each epoch processes the entire dataset once.\n",
        "\n",
        "Training Process:\n",
        "The Word2Vec model (w2v_model) is trained on the tokenized sentences provided in dataset[\"Summary_Stemmed\"].\n",
        "During training, the model learns to map words into a high-dimensional vector space such that words with similar contexts are closer in this space.\n",
        "\n",
        "Output:\n",
        "After training, w2v_model contains the learned word vectors that can be used to infer vectors for new words or sentences and perform similarity queries.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_nlHr_QDxpZ"
      },
      "source": [
        "**Save the trained word2vec model on the drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64CZ_l2Fyp7G"
      },
      "outputs": [],
      "source": [
        "# Save the Word2Vec model to a specified path on Google Drive\n",
        "model_path = '/content/drive/MyDrive/word2vec_model'\n",
        "w2v_model.save(model_path)\n",
        "\n",
        "\"\"\"\n",
        "Purpose:\n",
        "This code snippet saves the trained Word2Vec model (w2v_model) to a specified path on Google Drive.\n",
        "\n",
        "Parameters:\n",
        "model_path: Specifies the path where the Word2Vec model will be saved. It should include the desired file name or directory structure.\n",
        "\n",
        "Functionality:\n",
        "w2v_model.save(model_path): This method saves the trained Word2Vec model to the location specified by model_path.\n",
        "The model is typically saved in a format that includes both the trained word vectors and any additional metadata necessary for reloading the model.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ui7JlFwDxpc"
      },
      "source": [
        "**Load the trained word2vec model from the drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RzNgzZWPDSG"
      },
      "outputs": [],
      "source": [
        "# Load the Word2Vec model from a specified path on Google Drive\n",
        "model_path = '/content/drive/MyDrive/word2vec_model'\n",
        "w2v_model = Word2Vec.load(model_path)\n",
        "\"\"\"\n",
        "Purpose:\n",
        "This code snippet loads a pre-trained Word2Vec model (w2v_model) from a specified path on Google Drive.\n",
        "\n",
        "Parameters:\n",
        "model_path: Specifies the path from which the Word2Vec model will be loaded. It should point to the location where the model was previously saved.\n",
        "\n",
        "Functionality:\n",
        "Word2Vec.load(model_path): This function loads the Word2Vec model stored at model_path into memory.\n",
        "The loaded model can be used to perform tasks such as word vectorization, semantic similarity calculation, or any other operations supported by Word2Vec embeddings.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j70EtZ2QDxpc"
      },
      "source": [
        "**Convert each document to a fixed-size vector by averaging word vectors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5XTOHLqTInfn"
      },
      "outputs": [],
      "source": [
        "# Convert each document to a fixed-size vector by averaging word vectors\n",
        "def document_vector(w2v_model, doc):\n",
        "    \"\"\"\n",
        "    Generate a fixed-size vector representation for a document by averaging its word vectors.\n",
        "\n",
        "    Parameters:\n",
        "    - w2v_model (Word2Vec): The pre-trained Word2Vec model.\n",
        "    - doc (list of str): A list of words representing a document.\n",
        "\n",
        "    Returns:\n",
        "    - np.ndarray: A numpy array representing the document vector.\n",
        "    \"\"\"\n",
        "    # Filter out words not in the model's vocabulary\n",
        "    doc = [word for word in doc if word in w2v_model.wv]\n",
        "\n",
        "    # If the document has no words in the vocabulary, return a zero vector\n",
        "    if len(doc) == 0:\n",
        "        return np.zeros(w2v_model.vector_size)\n",
        "\n",
        "    # Calculate the mean of word vectors for the document\n",
        "    return np.mean(w2v_model.wv[doc], axis=0)\n",
        "\n",
        "# Apply document_vector function to each document in the dataset\n",
        "X = np.array([document_vector(w2v_model, doc) for doc in dataset[\"Summary_Stemmed\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QusNnxJRDxpd"
      },
      "source": [
        "**Split the dataset into training, validation and test sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xNWFW87T2r_-"
      },
      "outputs": [],
      "source": [
        "# Create the StratifiedShuffleSplit object\n",
        "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "# This line creates a StratifiedShuffleSplit object with the following parameters:\n",
        "# - n_splits=1: Specifies that there will be only one split.\n",
        "# - test_size=0.2: Indicates that 20% of the dataset will be used as the test set.\n",
        "# - random_state=42: Ensures reproducibility by using a fixed seed for the random number generator.\n",
        "\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "for train_val_index, test_index in sss1.split(X, y):\n",
        "    X_train_val, X_test = X[train_val_index], X[test_index]      # Features split\n",
        "    y_train_val, y_test = y.iloc[train_val_index], y.iloc[test_index]        # Labels split\n",
        "\n",
        "#for train_val_index, test_index in sss1.split(X, y):: Iterates over the indices generated by sss1.\n",
        "#X[train_val_index], X[test_index]: Splits the feature data X into X_train_val (train+validation) and X_test (test) sets based on the indices.\n",
        "#y.iloc[train_val_index], y.iloc[test_index]: Splits the label data y into y_train_val (train+validation) and y_test (test) sets using the corresponding indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "__r_SW452wQ3"
      },
      "outputs": [],
      "source": [
        "# StratifiedShuffleSplit setup for train and validation split\n",
        "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
        "# This line creates a new StratifiedShuffleSplit object specifically for splitting the initial training set\n",
        "# into train and validation sets with the following parameters:\n",
        "# - n_splits=1: Specifies that there will be only one split.\n",
        "# - test_size=0.2: Indicates that 20% of the training set will be used as the validation set.\n",
        "# - random_state=42: Ensures reproducibility by using a fixed seed for the random number generator.\n",
        "\n",
        "# Split the initial train set into train and validation sets\n",
        "for train_index, val_index in sss2.split(X_train_val, y_train_val):\n",
        "    X_train, X_val = X_train_val[train_index], X_train_val[val_index]        # Features split\n",
        "    y_train, y_val = y_train_val.iloc[train_index], y_train_val.iloc[val_index]          # Labels split\n",
        "\n",
        "# for train_index, val_index in sss2.split(X_train_val, y_train_val):: Iterates over the indices generated by sss2.\n",
        "# X_train_val[train_index], X_train_val[val_index]: Splits the feature data X_train_val into X_train (train) and X_val (validation) sets based on the indices.\n",
        "# y_train_val.iloc[train_index], y_train_val.iloc[val_index]: Splits the label data y_train_val into y_train (train) and y_val (validation) sets using the corresponding indices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJhb-p-w-e88"
      },
      "source": [
        "**Initialize and train an SVM Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "bMVkq31z-gpf",
        "outputId": "afcc8805-5576-4d8b-eb33-181ef3970d67"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nPurpose:\\n- Trains the SVM classifier on the training data.\\n\\nParameters:\\n- X_train: Training data vectors after applying word2vec.\\n- y_train: Training data labels.\\n\\nOutputs:\\n- Trained svm_classifier: SVM classifier fitted to the training data.\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(C = 1, kernel = 'linear')\n",
        "\"\"\"\n",
        "Purpose:\n",
        "- Initializes a Support Vector Machine (SVM) classifier with the specified parameters.\n",
        "\n",
        "Parameters:\n",
        "- C=10: Penalty parameter C of the error term.\n",
        "- kernel='linear': Specifies the linear kernel for the SVM.\n",
        "- probability=True: Enables probability estimation, necessary for Platt scaling.\n",
        "\n",
        "Outputs:\n",
        "- svm_classifier: Initialized SVM classifier object configured with specified parameters.\n",
        "\"\"\"\n",
        "\n",
        "# Train the classifier on the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\"\"\"\n",
        "Purpose:\n",
        "- Trains the SVM classifier on the training data.\n",
        "\n",
        "Parameters:\n",
        "- X_train: Training data vectors after applying word2vec.\n",
        "- y_train: Training data labels.\n",
        "\n",
        "Outputs:\n",
        "- Trained svm_classifier: SVM classifier fitted to the training data.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wZkbIsuDxpe"
      },
      "source": [
        "**Save the trained SVM model on the drive**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVmiKcLoYzDG",
        "outputId": "f11f4bd3-5060-4349-da20-b40b0ebd71fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/svm_classifier_model_word2vec.joblib']"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the model to Google Drive\n",
        "model_filename = '/content/drive/MyDrive/svm_classifier_model_word2vec.joblib'\n",
        "joblib.dump(svm_classifier, model_filename)\n",
        "\"\"\"\n",
        "Purpose:\n",
        "- Saves the trained SVM classifier model to a specified file location on Google Drive.\n",
        "\n",
        "Parameters:\n",
        "- svm_classifier: Trained SVM classifier object.\n",
        "- model_filename: File path where the trained model will be saved.\n",
        "\n",
        "Outputs:\n",
        "- Saved model file: Persists the trained SVM classifier to the specified file location.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z82UJoqB-8LE"
      },
      "source": [
        "**Evaluate the Classifier on the Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umjyytvDdHnC"
      },
      "outputs": [],
      "source": [
        "# Load the model from Google Drive\n",
        "model_filename = '/content/drive/MyDrive/svm_classifier_model_word2vec.joblib'\n",
        "svm_classifier = joblib.load(model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "ZiifYLID-9er",
        "outputId": "c198ece9-849d-4c34-9e4a-39568224c3da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6709090909090909\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nPurpose:\\n- Computes the accuracy of the SVM classifier on the validation set.\\n\\nParameters:\\n- y_val: True class labels of the validation set.\\n- val_predictions: Predicted class labels obtained from the SVM classifier.\\n\\nOutputs:\\n- Prints the validation accuracy score.\\n'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predict labels on the validation set\n",
        "val_predictions = svm_classifier.predict(X_val)\n",
        "\"\"\"\n",
        "Purpose:\n",
        "- Predicts the class labels for the validation set using the trained SVM classifier.\n",
        "\n",
        "Parameters:\n",
        "- svm_classifier: Trained SVM classifier object.\n",
        "- X_val: Validation set features.\n",
        "\n",
        "Outputs:\n",
        "- val_predictions: Predicted class labels for the validation set.\n",
        "\"\"\"\n",
        "\n",
        "# Calculate accuracy on the validation set\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\"\"\"\n",
        "Purpose:\n",
        "- Computes the accuracy of the SVM classifier on the validation set.\n",
        "\n",
        "Parameters:\n",
        "- y_val: True class labels of the validation set.\n",
        "- val_predictions: Predicted class labels obtained from the SVM classifier.\n",
        "\n",
        "Outputs:\n",
        "- Prints the validation accuracy score.\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
