{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "837wtVlaDoAm",
        "outputId": "510be6fe-32b3-4a89-86ff-83e7e5715811"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dDi2yE1u6d3",
        "outputId": "d704b1f9-a105-4e70-fb70-c55c508889bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting predict_developers.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile predict_developers.py\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import joblib\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import utils\n",
        "import tf_idf_utils\n",
        "\n",
        "# Define the prediction function to get top 5 classes\n",
        "def predict_top_5_classes(bug_report, svm_classifier, idf, default_idf, vocab, default_idx):\n",
        "    # Tokenize the new data\n",
        "    new_data_tokens = [tf_idf_utils.custom_tokenize(doc) for doc in bug_report]\n",
        "\n",
        "    # Compute TF-IDF for the new data using the loaded IDF\n",
        "    new_data_tfidf = [tf_idf_utils.compute_tfidf(tf_idf_utils.compute_tf(doc), idf, default_idf) for doc in new_data_tokens]\n",
        "    \n",
        "    # Convert the TF-IDF vectors to a sparse matrix\n",
        "    new_data_tfidf_matrix = tf_idf_utils.tfidf_to_sparse_matrix(new_data_tfidf, vocab, default_idx)\n",
        "\n",
        "    probabilities = svm_classifier.predict_proba(new_data_tfidf_matrix)[0]\n",
        "    top_5_indices = np.argsort(probabilities)[-5:][::-1]\n",
        "    return set(top_5_indices)\n",
        "\n",
        "# Function for inference based on bug report\n",
        "def Inference(bug_report, svm_classifier, idf, default_idf, vocab, default_idx):\n",
        "    # Tokenize the bug report\n",
        "    tokens = utils.tokenize_summary(bug_report)\n",
        "\n",
        "    # Remove stop words\n",
        "    tokens_without_stop_words = utils.remove_stopwords(tokens)\n",
        "\n",
        "    # Apply stemming\n",
        "    stemmed_tokens = utils.stem_tokens(tokens_without_stop_words)\n",
        "    \n",
        "    # Join tokens to form a string\n",
        "    joined_tokens = utils.join_tokens(stemmed_tokens)\n",
        "\n",
        "    # Predict the top 5 classes using the svm_classifier after applying TF-IDF\n",
        "    top_5_classes = predict_top_5_classes(joined_tokens, svm_classifier, idf, default_idf, vocab, default_idx)\n",
        "\n",
        "    return top_5_classes\n",
        "\n",
        "def main():\n",
        "    # Load the claddifier, TF-IDF vectorizer and label encoder\n",
        "    svm_classifier = joblib.load('svm_classifier_model_with_tf_idf_implementation_final.joblib')\n",
        "\n",
        "    # Load the tfidf components\n",
        "    idf, default_idf, vocab, default_idx = joblib.load('custom_tfidf_vectorizer_final.pkl')\n",
        "    # Load and parse the input data\n",
        "    data = json.loads(sys.argv[1])\n",
        "    bug_description = data[\"bugDescription\"]\n",
        "\n",
        "    # Perform inference to predict top 5 classes for the input bug description\n",
        "    input_bug_top_5_classes = Inference(bug_description, svm_classifier, idf, default_idf, vocab, default_idx)\n",
        "\n",
        "    # Dictionary to store the number of common classes for each developer\n",
        "    developers_bugs_classes = {}\n",
        "\n",
        "    # Set to store developers with no bugs solved\n",
        "    developers_with_no_bugs = set()\n",
        "\n",
        "    # Iterate over developers' data\n",
        "    for developer in data[\"developersData\"]:\n",
        "        developer_id = developer[\"developerID\"]\n",
        "        old_bugs = developer[\"oldBugsDescription\"]\n",
        "\n",
        "        # Check if the developer has no old bugs\n",
        "        if not old_bugs:\n",
        "            developers_with_no_bugs.add(developer_id)\n",
        "            continue\n",
        "\n",
        "        # Count common classes between input bug and each old bug\n",
        "        common_classes_count = 0\n",
        "        for bug in old_bugs:\n",
        "            predicted_top_5_classes = Inference(bug, svm_classifier, idf, default_idf, vocab, default_idx)\n",
        "            common_classes = input_bug_top_5_classes.intersection(predicted_top_5_classes)\n",
        "            common_classes_count += len(common_classes)\n",
        "\n",
        "        # Store the total common classes count for the developer\n",
        "        developers_bugs_classes[developer_id] = common_classes_count\n",
        "\n",
        "    # Sort developers by common class counts in descending order\n",
        "    sorted_developers = sorted(developers_bugs_classes.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    # Get the top developers (at most 5)\n",
        "    num_top_developers = min(5, len(sorted_developers))\n",
        "\n",
        "    # Get the top 5 developers based on common class counts\n",
        "    recommended_developers = [developer_id for developer_id, _ in sorted_developers[:num_top_developers]]\n",
        "\n",
        "    # Ensure that all developers with no bugs are considered for recommendation\n",
        "    if developers_with_no_bugs:\n",
        "      if(len(recommended_developers)==5):\n",
        "        # Replace the last recommendation with a developer with no bugs\n",
        "        recommended_developers[4] = developers_with_no_bugs.pop()\n",
        "      else:\n",
        "        # Add developers with no bugs until the recommended list reaches 5 developers\n",
        "        while(len(recommended_developers) < 5 and developers_with_no_bugs):\n",
        "          recommended_developers.append(developers_with_no_bugs.pop())\n",
        "\n",
        "    # Print the recommended developers\n",
        "    print(\"Recommended Developers:\", recommended_developers)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s96__oNmztih",
        "outputId": "541a48e6-03cc-4ec9-bdd7-446acebc340a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Recommended Developers: ['667a760a6da0c47fe0a327cd', '667a76f471631147e0b6e0d6', '667a76f471631147e0b6e0dbbd', '667a76f471631147e0b6e0deedd', '667a76f471631147e0b6e0ddd']\n"
          ]
        }
      ],
      "source": [
        "!python predict_developers.py '{\"bugDescription\": \"Maximize on second larger monitor not working \", \"developersData\": [{\"developerID\": \"667a76f471631147e0b6e0d\", \"jobTitle\": \"Backend Developer\", \"oldBugsDescription\": []},{\"developerID\": \"667a76f471631147e0b6e0ddd\", \"jobTitle\": \"Backend Developer\", \"oldBugsDescription\": []},{\"developerID\": \"667a76f471631147e0b6e0dbbd\", \"jobTitle\": \"Backend Developer\", \"oldBugsDescription\": []},{\"developerID\": \"667a76f471631147e0b6e0deedd\", \"jobTitle\": \"Backend Developer\", \"oldBugsDescription\": []},{\"developerID\": \"667a760a6da0c47fe0a327cd\", \"jobTitle\": \"Backend Developer\", \"oldBugsDescription\": [\"Maximize on second larger monitor not working\", \"the font size is very small\"]}, {\"developerID\": \"667a76f471631147e0b6e0d6\", \"jobTitle\": \"Backend Developer\", \"oldBugsDescription\": [\"Manual guide installation is not clear\"]}]}'"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
